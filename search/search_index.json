{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ALICE Software on Github","text":"<p> The ALICE Collaboration has built a dedicated detector to exploit the unique physics potential of nucleus-nucleus collisions at LHC energies. Our aim is to study the physics of strongly interacting matter at the highest energy densities reached so far in the laboratory. In such condition, an extreme phase of matter - called the quark-gluon plasma - is formed. Our universe is thought to have been in such a primordial state for the first few millionths of a second after the Big Bang. The properties of such a phase are key issues for Quantum Chromo Dynamics, the understanding of confinement-deconfinement and chiral phase transitions. For this purpose, we are carrying out a comprehensive study of the hadrons, electrons, muons and photons produced in the collisions of heavy nuclei. ALICE is also studying proton-proton and proton-nucleus collisions both as a comparison with nucleus-nucleus collisions and in their own right. This page hosts the software for RUN1 and RUN2 of the experiment, AliRoot (ALICE Offline Framework) and AliPhysics (ALICE Analysis repository). </p> <p>You can find a basic tutorial on how to use the software here, and an advanced tutorial here.</p>"},{"location":"about/","title":"About","text":"<p>These pages are still work in progress, they represent the  log of my work to setup the ALICE build infrastructure.</p>"},{"location":"aliphysics-ci/","title":"AliPhysics CI and Release Validation","text":""},{"location":"aliphysics-ci/#checking-the-status-of-the-daily-builds","title":"Checking the status of the daily builds","text":"<p>Daily build are built with Jenkins. You can check the status of the current build and the logs of previous one by going to:</p> <p>https://alijenkins.cern.ch/job/daily-builds/job/daily-aliphysics-github/</p>"},{"location":"aliphysics-ci/#trying-out-a-release-validation","title":"Trying out a Release Validation","text":"<p>If a release validation fails, one can try out the release candidate by sourcing the nightly environment from CVMFS:</p> <pre><code>source /cvmfs/alice-nightlies.cern.ch/etc/login.sh\nexport PATH=/cvmfs/alice-nightlies.cern.ch/bin:$PATH\n</code></pre> <p>then you can query and use nightly releases the usual way:</p> <pre><code>alienv q | grep &lt;name of the release&gt;\nalienv enter &lt;name of the release&gt;\n</code></pre>"},{"location":"ci/","title":"Continuous Integration","text":"<p>You can find in this section a few information on how do use continuous integration builds and release validation for various ALICE software:</p> <ul> <li>AliPhysics</li> </ul>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#how-do-i-install-the-builds-done-by-the-automatic-system","title":"How do I install the builds done by the automatic system?","text":"<p>If you only need to run your root macro on top of some prebuild AliPhysics and you do not have access to CVMFS, which remains the preferred, supported and recommended way of getting ALICE software, you can try using the prebuild tarballs which you can find at:</p> <p>https://ali-ci.cern.ch/repo/TARS/&lt;architecture&gt;/dist-runtime/</p> <p>e.g., for CERN Centos 7:</p> <p>https://ali-ci.cern.ch/repo/TARS/slc7_x86-64/dist-runtime/</p> <p>(other architectures can be found in https://ali-ci.cern.ch/repo/TARS/).</p> <p>If you have a RPM based distribution and you wish to try it out, please have a look at the instructions provided here:</p> <p>https://aliceo2group.github.io/quickstart/binaries.html</p>"},{"location":"faq/#how-do-i-build-aliroot-o2-using-alibuild","title":"How do I build AliRoot / O2 using alibuild?","text":"<p>In order to build ALICE packages, you can use the following recipe:</p> <pre><code># Clone our build tool\ngit clone --origin upstream https://github.com/alisw/alibuild\n# Clone our build recipes\ngit clone --origin upstream https://github.com/alisw/alidist\n# Optional: clone O2 or any other package you want to develop.\n#           aliBuild will prefer your copy to the one specified in the\n#           recipe\ngit clone --origin upstream -b dev https://github.com/AliceO2Group/AliceO2 O2\n# Start the build\nalibuild/aliBuild --debug --jobs NJOBS build O2\n</code></pre> <p>the software will be compiled, by default, in the <code>sw</code> directory. Use</p> <pre><code>WORK_DIR=$PWD source sw/&lt;architecture&gt;/O2/latest/etc/profile.d/init.sh\n</code></pre> <p>to have the environment setup. For example on OSX:</p> <pre><code>WORK_DIR=$PWD source sw/osx_x86-64/O2/latest/etc/profile.d/init.sh\n</code></pre> <p>If you want to develop, you can change the sources in the O2 folder and then</p> <pre><code>cd sw/&lt;architecture&gt;/BUILD/O2/latest &amp;&amp; make -j 20 install\n</code></pre> <p>For more details about alibuild you can look at:</p> <pre><code>http://alisw.github.io/alibuild\n</code></pre>"},{"location":"git-advanced/","title":"GitHub advanced workflow","text":"<p>This guide is meant to be a set of advanced topics regarding the ALICE Github workflow. If you are looking for a more step-by-step guide on how to get started and propose code changes to AliPhysics, please start from the basic GitHub workflow.</p>"},{"location":"git-advanced/#i-want-to-use-the-command-line","title":"I want to use the command line!","text":"<p>If you find the web based workflow not matching your taste, GitHub offers the possibility to use a command-line based workflow as well via a utility called <code>hub</code> .</p>"},{"location":"git-advanced/#install-hub","title":"Install hub","text":"<p>On macOS you can install it with brew:</p> <pre><code>brew install hub\n</code></pre> <p>On Linux you can use the precompiled releases. After you have installed hub, the <code>hub</code> command will be available. Note that the hub documentation suggests you configure <code>git</code> as an alias to <code>hub</code> in your shell configuration:</p> <pre><code>alias git=hub\n</code></pre> <p>This way you can \u201cextend\u201d the <code>git</code> command functionalities with the ones offered by <code>hub</code> seamlessly. We will not assume the alias is configured in this document.</p>"},{"location":"git-advanced/#forking-and-cloning-the-repository","title":"Forking and cloning the repository","text":"<p>In order to fork a repository you can use <code>hub fork</code> and <code>hub clone</code>. The following example clones the official AliPhysics repository and configures your own fork (the <code>user.github</code> Git configuration parameter must be set as suggested in the basic workflow documentation). Note that your fork is created on your GitHub account in case it does not exist:</p> <pre><code>cd ~/alice\nhub clone alisw/AliPhysics\nhub fork\n</code></pre>"},{"location":"git-advanced/#creating-a-pull-request","title":"Creating a pull request","text":"<p>The second step to request your changes to be tested and reviewed in order to be included upstream. This is done by typing:</p> <pre><code>hub pull-request\n</code></pre> <p>The command above allows you to do so without leaving the terminal. The output of the command above will be a URL like:</p> <pre><code>https://github.com/alisw/AliPhysics/pull/12\n</code></pre> <p>If you copy-paste it to your browser you will see the GitHub interface for the opened pull request, which is the same as if you had opened it via the web interface.</p>"},{"location":"git-advanced/#how-to-write-a-pull-request","title":"How to write a pull request","text":"<p>Try to be short (stay within 50 characters) and concise in the title, and save any elaboration for the description.</p> <p>A good example is:</p> <ul> <li>Title: Fix missing particles in the decay table</li> <li>Description: Warning messages about missing particle entries during the   ppbench are fixed.</li> </ul> <p>A bad example is:</p> <ul> <li>Title: A fix</li> <li>Description: <p>You should elaborate what the fix is for at least.</p> <p>Another bad example is:</p> <ul> <li>Title: Fix missing particles in the decay table that caused ppbench to   complain a lot with warning messages</li> <li>Description: <p>The title is too long, and most of what it says can be moved to the description field.</p>"},{"location":"git-advanced/#how-to-use-large-data-files-for-analysis","title":"How to use large data files for analysis","text":"<p>Some large OADB files were removed from AliPhysics and they are no longer available in the Git repository. Those files are not lost; they have been moved to the following EOS location, which is accessible from lxplus:</p> <pre><code>/eos/experiment/alice/analysis-data\n</code></pre> <p>We have preserved the same directory structure found on AliPhysics, and the same permissions: for instance, <code>PWGLF</code> is writable by all members of <code>alice-svn-pwglf</code> (whose members can be edited by the group conveners).</p> <p>Every day, in concomitance with the AliPhysics daily tag (at 4pm Geneva time), this folder is snapshotted on CVMFS under the following path:</p> <pre><code>/cvmfs/alice.cern.ch/data/analysis/YYYY/vAN-YYYYMMDD\n</code></pre> <p>carrying the same name as the corresponding AliPhysics tag. Moreover, at every AliRoot/AliPhysics production release, we also snapshot at:</p> <pre><code>/cvmfs/alice.cern.ch/data/prod/v5-XX-YY-01\n</code></pre> <p>where the last component is the AliPhysics tag name.</p> <p>CVMFS brings the advantage to make data access from Grid jobs reliable and faster due to caching (files unchanged in two different snapshots are not downloaded twice).</p> <p>In order to profit from the separate storage for large files we have created an interface in AliRoot to allow transparent access to OADB files using a relative path. For instance, if you want to access the following large OADB data file:</p> <pre><code>PWGLF/FORWARD/CORRECTIONS/data/fmd_corrections.root\n</code></pre> <p>you can do:</p> <pre><code>TFile::Open(AliDataFile::GetFileNameOADB(\"PWGLF/FORWARD/CORRECTIONS/data/fmd_corrections.root\"))\n</code></pre> <p>The static function <code>AliDataFile::GetFileNameOADB</code> returns the first accessible full URL of the OADB file by finding the first match from the following ordered list of paths:</p> <ol> <li><code>$OADB_PATH/&lt;file&gt;</code></li> <li><code>$ALICE_DATA/OADB/&lt;file&gt;</code></li> <li><code>$ALICE_PHYSICS/OADB/&lt;file&gt;</code></li> <li><code>/cvmfs/alice.cern.ch/data/prod/v5-XX-YY-01/OADB/&lt;file&gt;</code> (for Grid jobs, or with CVMFS installed)</li> <li><code>/cvmfs/alice.cern.ch/data/analysis/YYYY/vAN-YYYYMMDD/OADB/&lt;file&gt;</code> (for Grid jobs, or with CVMFS installed)</li> <li><code>root://eospublic.cern.ch//eos/experiment/alice/analysis-data/OADB/&lt;file&gt;</code></li> </ol> <p>This means that for laptop analysis it will always be possible to access data files, somehow, and in a transparent fashion. If you want to have your OADB data locally, you can download it from lxplus:</p> <pre><code>export OADB_PATH=/path/to/my/local/oadb\nrsync -av --delete cern_user@lxplus.cern.ch:/eos/experiment/alice/analysis-data/ $OADB_PATH/\n</code></pre> <p>Trailing slashes are important to rsync! Do not forget them!</p> <p>Note that the variable <code>$OADB_PATH</code> must be exported to the environment where you run your local analysis in order to make it visible to the job.</p>"},{"location":"git-advanced/#non-oadb-data-files","title":"Non-OADB data files","text":"<p>The same EOS path has also PWG-specific directories, outside the OADB one, for other analysis-specific data. The following interface can be used to access files from there:</p> <pre><code>TFile::Open(AliDataFile::GetFileName(\"PWGMM/my_large_data.root\"))\n</code></pre> <p>Note the difference between <code>GetFileName()</code> and <code>GetFileNameOADB()</code>.</p> <p>In this case, the file will be searched in the following locations in order:</p> <ol> <li><code>$ALICE_DATA/&lt;file&gt;</code></li> <li><code>$ALICE_PHYSICS/&lt;file&gt;</code></li> <li><code>/cvmfs/alice.cern.ch/data/prod/v5-XX-YY-01/&lt;file&gt;</code> (for Grid jobs, or with CVMFS installed)</li> <li><code>/cvmfs/alice.cern.ch/data/analysis/YYYY/vAN-YYYYMMDD/&lt;file&gt;</code> (for Grid jobs, or with CVMFS installed)</li> </ol>"},{"location":"git-advanced/#git-editors-plugins","title":"Git editors plugins","text":"<p>Many Git plugins exist in order to improve your Git workflow from within your favorite editor. Examples of what you can do with such plugins are seeing what parts of code were added or removed by you before committing them, or perform the commit of some portions of your modifications.</p> <ul> <li>Magit for Emacs</li> <li>GitGutter for Sublime or   Vim</li> </ul>"},{"location":"git-advanced/#work-with-multiple-branches","title":"Work with multiple branches","text":"<p>The basic workflow we suggest is to use a single branch and develop one feature at a time. If you follow this workflow then your local branch will be called <code>master</code>, and so are called the remote working branch on your fork, and the remote upstream branch.</p> <p>You may want to develop multiple features at the same time because you do not want to wait for one feature to be merged before proceeding, for instance.</p> <p>To do so, the first thing to do is make sure your local <code>master</code> branch is up-to-date:</p> <pre><code>cd ~/alice/AliPhysics\ngit checkout master\ngit pull --rebase upstream master\n</code></pre> <p>Now from your <code>master</code> branch, spawn a different one, and name it explicitly:</p> <pre><code>git checkout -b my-new-feature\n</code></pre> <p>The <code>git checkout -b</code> command creates the <code>my-new-feature</code> branch (the name is arbitrary) and moves you to it. You can check at any time what is your current branch at any time with:</p> <pre><code>git status\n</code></pre> <p>which will give you something like:</p> <pre><code>On branch my-new-feature\nnothing to commit, working directory clean\n</code></pre> <p>At this point you can start developing your code, and make your commits as usual with <code>git commit</code>. When it comes the time for pushing, you need to tell Git that you want to push your current branch to a remote branch with the same name (for simplicity) on your remote fork. This is done by:</p> <pre><code>git push --set-upstream origin my-new-feature\n</code></pre> <p>Note that all subsequent pushes from this branch can be simply done with:</p> <pre><code>git push\n</code></pre> <p>as you have already told Git what is the corresponding upstream branch once.</p> <p>When you need to create a pull request you can simply do it from the command line in case you have Hub installed:</p> <pre><code>hub pull-request\n</code></pre> <p>and it will return you the link (to copy and paste into your browser) to the GitHub page corresponding to the newly created pull request. In case you want to use the interface, go to your fork from a browser:</p> <p>https://github.com/\\&lt;your-github-username&gt;/AliPhysics</p> <p>From the web interface you will see something like the following:</p> <p></p> <p>If you have recently pushed, which is the case most of the time, GitHub tells you what is your branch name and proposes you to open the pull request right away, as you can see from the yellow box. You just need to press the green button indicated by the red arrow. This is very convenient.</p> <p>In case you are not presented with a direct link, then use the dropdown to select your branch explicitly (see the other red arrow). Once you have done that just click the \"New pull request\" button next to the dropdown and continue with the normal workflow.</p> <p>As explained already in order to amend or integrate an open pull request just keep committing and pushing on the corresponding feature branch.</p> <p>While you are working on a certain feature on a branch different from <code>master</code> you can work on other features. You don't need to push your current changes, and you don't need to open a pull request either: just commit all your changes with, for instance:</p> <pre><code>git add --all -v :/\ngit commit\n</code></pre> <p>in order to be able to cleanly switch to a different branch (if you don't want to commit you can use the stash too).</p> <p>Now switch back to <code>master</code>, update it, and create a new branch from there:</p> <pre><code>git checkout master\ngit pull --rebase upstream master\ngit checkout -b my-second-feature\n</code></pre> <p>You can now follow the same workflow, by keeping in mind that you can switch back and forth using <code>git checkout</code> (without the <code>-b</code> option this time).</p> <p>It is important you create your feature branches from an updated <code>master</code>, and not from other feature branches, in order to avoid confusion and in order to avoid opening different pull requests with overlapping contents.</p> <p>The advantage of this workflow is that you will never work in your <code>master</code> branch (i.e. you will never perform <code>git push</code> from there): your changes and the upstream ones are clearly separated.</p>"},{"location":"git-advanced/#clean-up-feature-branches","title":"Clean up feature branches","text":"<p>Once your pull requests get merged, you can delete both your local feature branch and the remote counterpart. Note that this is completely optional.</p> <p>To delete your local branch, first move to the <code>master</code> and update it:</p> <pre><code>git checkout master\ngit pull --rebase upstream master\n</code></pre> <p>then delete it:</p> <pre><code>git branch -d my-feature-branch\n</code></pre> <p>If your branch was merged to <code>master</code> then Git will not complain. If your branch was not merged, Git will prevent you from accidentally delete it (you can force by using <code>-D</code> instead of <code>-d</code> if you really know what you are doing).</p> <p>Now you can delete the remote one (this is a dangerous and irreversible operation):</p> <pre><code>git push origin :my-feature-branch\n</code></pre> <p>It's the <code>:</code> that does the trick (it's not a typo).</p>"},{"location":"git-advanced/#port-unpushed-old-commits-to-github","title":"Port unpushed old commits to GitHub","text":"<p>In case you have local Git commits you did not push in your old AliPhysics repository and you would like to push them to GitHub now, you can create a \"patch\" from your old local repository and apply it on top of your local GitHub copy of AliPhysics.</p> <p>Go in your old AliPhysics repository (assumed to be in <code>~/alice-old</code>):</p> <pre><code>cd ~/alice-old/AliPhysics\ngit format-patch HEAD^1\n</code></pre> <p>The <code>HEAD^1</code> means: take the first commit on top. If you have more than one commit to port, replace <code>1</code> with the appropriate number.</p> <p>You will find in your current directory a number of <code>.patches</code> files. If you have your new AliPhysics directory under <code>~/alice</code>, you can go there and apply all of them at once, after making sure you have all the upstream changes locally:</p> <pre><code>cd ~/alice\ngit checkout master\ngit pull --rebase upstream master\ngit am ~/alice-old/AliPhysics/*.patch\n</code></pre> <p>Note that this command assumes that the only <code>.patches</code> files you have in your old AliPhysics directory are the ones you have just created with <code>git format-patch</code>.</p> <p>At this point you can push to your local fork and create a pull request:</p> <pre><code>git push origin\nhub pull-request -b alisw/AliPhysics:master\n</code></pre> <p>The <code>hub</code> command works if you have the command line tool installed, otherwise just follow the web-based procedure.</p>"},{"location":"git-advanced/#rebuild-an-old-alirootaliphysics-release","title":"Rebuild an old AliRoot/AliPhysics release","text":"<p>GitHub clones are only valid for building AliRoot/AliPhysics releases from v5-09 on. Due to the repository cleanup, checking out an older version will lead to inconsistent results.</p> <p>Suppose you want to build version v5-08-18 of AliRoot (corresponding to v5-08-18-01 of AliPhysics). In a separate directory, called <code>~/alice-legacy</code>, you can do:</p> <pre><code>mkdir ~/alice-legacy &amp;&amp; cd ~/alice-legacy\naliBuild --dist IB/v5-08/prod init AliRoot,AliPhysics\n</code></pre> <p>Then you can explicitly checkout the versions you need:</p> <pre><code>cd ~/alice-legacy/AliRoot\ngit checkout v5-08-18\ncd ~/alice-legacy/AliPhysics\ngit checkout v5-08-18-01\n</code></pre> <p>Now you can run aliBuild as usual:</p> <pre><code>cd ~/alice-legacy\naliBuild build AliPhysics\n</code></pre> <p>The trick is using the recipes set (alidist) from the branch <code>IB/v5-08/prod</code>, which has the correct pointers to the frozen old clones of AliRoot and AliPhysics.</p>"},{"location":"git-advanced/#use-the-reference-ocdb","title":"Use the reference OCDB","text":"<p>Our production OCDB is stored on CVMFS and AliEn, however we also have a reference OCDB which used to be part of AliRoot. The reference OCDB is no longer there: it can now be found at this separate Git repository.</p> <p>To use the new OCDB with AliPhysics, you first need to build the package:</p> <pre><code>cd ~/alice\naliBuild build AliPhysics\naliBuild build AliRoot-OCDB\n</code></pre> <p>When you enter the environment, load it as extra package:</p> <pre><code>cd ~/alice\nalienv enter AliPhysics/latest AliRoot-OCDB/latest\n</code></pre> <p>The OCDB will be available at the following path:</p> <pre><code>$ALIROOT_OCDB_ROOT/OCDB\n</code></pre> <p>so you will need to update your paths accordingly. If you don't use aliBuild you can simply clone the package and manually export the environment variable:</p> <pre><code>cd ~/alice\ngit clone --origin upstream https://gitlab.cern.ch/alisw/AliRootOCDB.git\nexport ALIROOT_OCDB_ROOT=$PWD/AliRootOCDB\n</code></pre> <p>Note that <code>ALIROOT_OCDB_ROOT</code> is the toplevel directory containing in turn the <code>OCDB</code> directory with the calibration files.</p>"},{"location":"git-advanced/#setup-a-git-credentials-cache","title":"Setup a Git credentials cache","text":"<p>While compiling the AliRoot/AliPhysics software chain you might be asked several times to input your CERN username and your password. This is because some of the required software components have licensing restrictions and cannot be made publicly available, so authentication is an inevitable consequence. This happens for instance with the DPMJET generator.</p> <p>To prevent automated installations from bothering you with multiple password requests, you can set up a Git credentials cache.</p> <p>You can do (only once):</p> <pre><code>git config --global credential.helper \"cache --timeout=86400\"\n</code></pre> <p>to tell Git to save in memory all inputted credentials for one day. You will be prompted for your password only once in 24 hours, or if your password changes and the cached one is no longer valid.</p> <p>The cache duration can be configured with the <code>--timeout</code> switch and it is is expressed in seconds.</p> <p>A very unsafe option is to permanently store your password in <code>~/.git-credentials</code>: you will be prompted only once, and the password will be forever stored there in clear text.</p> <pre><code>git config --global credential.helper store\n</code></pre> <p>Note: this solution is not good for your laptop. It is meant to target clusters with unattended installation systems.</p> <p>If you are on macOS you can also save your Git password inside your Keychain:</p> <pre><code>git config --global credential.helper osxkeychain\n</code></pre> <p>More information on caching Git credentials can be found on the GitHub documentation: the documentation applies also to repositories not hosted on GitHub.</p>"},{"location":"git-advanced/#get-notified-for-all-changes","title":"Get notified for all changes","text":"<p>Email notifications are handled by GitHub and will be sent to the email you have linked to your GitHub account.</p> <p>If you want to be notified for every activity on a certain repository, you first need to make sure \"watch\" notifications are enabled. Go to the GitHub notification settings page for your account, and enable email notifications for Watching:</p> <p></p> <p>A green tick will appear next to the checkboxes to confirm your settings have been saved (there is no \"save settings\" button).</p> <p>Note that in the GitHub notification settings you can granularily specify what are the events that trigger a notification. You can for instance be notified only for pushes or merges, and not for every comment.</p> <p>Note that independently from your \"Watch\" settings, you will continue receiving emails if you are @mentioned if the Participating settings are ticked.</p> <p>Navigate now to the repository you want to follow, for instance AliPhysics and on the dropdown on top select Watch to be notified of all activities.</p> <p></p>"},{"location":"git-tutorial/","title":"GitHub basic workflow","text":""},{"location":"git-tutorial/#what-are-these-instructions-for","title":"What are these instructions for?","text":"<p>These instructions are meant to be the simplest way to get you up and running developing one feature at the time for AliPhysics on GitHub. They can be reused for AliRoot by simply changing AliPhysics to AliRoot. If you are trying to do something more complicated or you want to have more detailed information on the inner workings of the system, please refer to the advanced workflow instead.</p>"},{"location":"git-tutorial/#setup-github-account","title":"Setup GitHub account","text":"<p>The first thing you need to do is to create an account there and to map your CERN account to a GitHub one. This is a one time operation. You can do the mapping by going to:</p> <p>https://alisw.cern.ch/alice-github/login</p> <p>In case you don\u2019t have a GitHub account you will be asked to create one. Notice there is no need for a paying account: a free GitHub account is sufficient to work on ALICE software.</p> <p>Note: we recommend you create a GitHub username which is the same as your CERN one, if available.</p> <p></p> <p>In case you have an account, login and authorize \u201cALICE Continuous Integration\u201d to read your user name so that it can be mapped to your CERN account.</p> <p></p>"},{"location":"git-tutorial/#fork-a-repository","title":"Fork a repository","text":"<p>\u201cForking\u201d a repository in GitHub means that you create a remote copy of some official (i.e. upstream) repository in your own account. This copy is linked to the original repository and allows you to propose changes in the form of a so-called \u201cPull Request\u201d.</p> <p>To fork AliPhysics you can point your browser to:</p> <p>https://github.com/alisw/AliPhysics/fork</p> <p>and follow the instructions.</p>"},{"location":"git-tutorial/#setup-user-configuration-on-your-local-computer","title":"Setup user configuration on your local computer","text":"<p>Initial setup:</p> <pre><code>git config --global user.name \"&lt;Firstname&gt; &lt;Lastname&gt;\"\ngit config --global user.email &lt;your-email-address&gt;\ngit config --global user.github &lt;your-github-username&gt;\n</code></pre> <p>Note that the <code>--global</code> flag sets those parameters for every Git repository on your laptop. Depending on the number of Git projects you contribute to you might want to set such options per repository.</p> <p>The <code>user.name</code> will appear in every commit you make. Note that the old configuration suggested you used your CERN account name, whereas we now suggest you configure it with your \u201cFirstname Lastname\u201d.</p> <p>It is probably convenient to setup a passwordless login for GitHub using SSH, otherwise you need to type your password on each operation. If you already have a SSH key have a look at these instructions. More details on GitHub and SSH are also available.</p>"},{"location":"git-tutorial/#credentials-for-private-repositories","title":"Credentials for private repositories","text":"<p>A full AliRoot/AliPhysics build requires manually inputting your CERN username and password in some cases, as it is stored on private ALICE Git repositories hosted at CERN GitLab.</p> <p>In order to access them, you need to login to gitlab.cern.ch at least once using your browser in order to be registered, otherwise you will not be able to download private components! After you have done that for the first time you need to wait for up to one hour before you can download the code. This is explained on this CERN IT-maintained documentation.</p> <p>During the compilation process you might be asked several times for your CERN credentials. To avoid repeating the procedure several times, and to prevent unattended builds to wait for your input, you can setup a temporary or permanent credentials cache. Note that the credentials cache is also an alternative to setting up a GitHub SSH key.</p>"},{"location":"git-tutorial/#setup-software-repositories-on-your-local-computer","title":"Setup software repositories on your local computer","text":"<p>We recommend to follow the ALICE Analysis Tutorial. Alternatively, see further below if you want to check out the repository manually.</p> <p>With older versions of aliBuild, the central remote repository (used for pulling updates) would be called <code>origin</code> instead of the usual name <code>upstream</code> and the personal (fork) remote repository (used for pushing changes) would be called <code>&lt;your-github-username&gt;</code> instead of the usual name <code>origin</code>. Please check your settings using <code>git remote -v</code> and adjust the Git commands mentioned in the following instructions accordingly, if needed.</p> <p>We will assume from now on that your working directory is <code>~/alice</code>. If you have your old installation under <code>~/alice</code> then we suggest you use a different directory to avoid confusion.</p>"},{"location":"git-tutorial/#i-have-participated-to-the-github-test","title":"I have participated to the GitHub test","text":"<p>If you have participated to the GitHub test and you want to sync with the current official AliRoot/AliPhysics and alidist repositories from upstream, you can now follow this procedure which might save you some build time.</p> <p>Assuming you have your GitHub test installation under <code>~/alice</code>, destroy your current recipes, AliRoot and AliPhysics directories:</p> <pre><code>cd ~/alice\nrm -rf alidist/ AliRoot/ AliPhysics/\n</code></pre> <p>Then clone AliRoot and AliPhysics from GitHub:</p> <pre><code>cd ~/alice\ngit clone --origin upstream https://github.com/alisw/AliRoot\ngit clone --origin upstream https://github.com/alisw/AliPhysics\n</code></pre> <p>If you use aliBuild you can skip the two clones and do directly:</p> <pre><code>cd ~/alice\naliBuild init AliRoot,AliPhysics\n</code></pre> <p>You may now setup your repositories and update your fork with changes from the master, and you will be ready to build, and create pull requests.</p>"},{"location":"git-tutorial/#contribute-to-alice-software","title":"Contribute to ALICE software","text":"<p>Now if you want to contribute to AliPhysics move to the clone directory and tell Git about the existence of your own fork, created in a previous step.</p> <p>If you use SSH (recommended, especially if you are using a slow or unreliable connection):</p> <pre><code>cd ~/alice/AliPhysics\ngit remote add origin git@github.com:&lt;your-github-username&gt;/AliPhysics.git\n</code></pre> <p>If you do not use SSH:</p> <pre><code>cd ~/alice/AliPhysics\ngit remote add origin https://github.com/&lt;your-github-username&gt;/AliPhysics\n</code></pre>"},{"location":"git-tutorial/#updating-your-fork-with-changes-from-the-master","title":"Updating your fork with changes from the master","text":"<p>While you are working, other people may propose code for inclusion in the master. You can update your local repository and your fork with the latest version of the master with the following lines:</p> <pre><code>cd ~/alice/AliPhysics\ngit pull --rebase upstream master\ngit push origin\n</code></pre> <p>Note that if you are in the middle of your work (i.e. you have your changes already pushed to your forked repository which are not yet merged), you might need to perform a \u201cforce push\u201d, as the <code>--rebase</code> option may change your local Git history:</p> <pre><code>git push -f origin\n</code></pre> <p>You should use the <code>-f</code> switch only when needed and if you are sure you are not going to destroy any of your changes first.</p> <p>Note that you don\u2019t need to pull from upstream every time you need to push your changes. This is a big improvement over the old workflow where you had to pull before you could push, which could happen frequently when the daily tag time approached.</p>"},{"location":"git-tutorial/#workflow-to-commit-your-changes","title":"Workflow to commit your changes","text":"<p>As depicted in the image, the general idea is:</p> <ul> <li>you always fetch the changes (\u201cpull\u201d) from the upstream repository</li> <li>you always write your changes (\u201cpush\u201d) to your own fork</li> <li>you propose the changes to be added upstream by opening a \u201cpull request\u201d</li> <li>your code change proposal is checked by a series of automatic tests before   being accepted (more details follow)</li> </ul> <p>What we illustrate here is a simplified workflow, where you work on a single branch. The workflow is simpler, but it has limitations you need to know.</p> <ul> <li>If you work on one feature at a time this is enough. When you open the   pull request, though, you will have to wait until it is accepted and merged   before starting developing new features. This is because each pull request is   tied to your remote <code>master</code>, and if you push to it you are updating the   existing pull request. For the same reason, if you follow this workflow you   cannot open multiple pull requests at the same time because you need multiple   branches for that.</li> <li>If you need to work on multiple features at the same time then you will   need to work with multiple branches (advanced   documentation).</li> </ul> <p>It is important to stress that if you have an open (not yet merged) pull request following this simplified workflow and you push new changes, then the open pull request gets updated and tests will start over!</p>"},{"location":"git-tutorial/#create-a-pull-request","title":"Create a pull request","text":"<p>Let\u2019s say you have a development to AliPhysics you want to propose for inclusion. This is done with a \u201cpull request\u201d. In order to create one you need to do the following. First off, commit the changed files and push them to your fork:</p> <pre><code>cd ~/alice/AliPhysics\ngit add &lt;file&gt;  # possibly several times\ngit commit\ngit push origin\n</code></pre> <p>At this point changes are on your own fork on GitHub, and they are not yet upstream. This means they will not be included in the daily tag, for the moment. It is important to understand this point as this is the main difference to the old workflow. To get your changes included, you need to create a pull request by going to:</p> <p>https://github.com/\\&lt;your-github-username&gt;/AliPhysics</p> <p>then click on \u201cNew pull request\u201d:</p> <p></p> <p>Review the proposed changes and if you are satisfied click on the green button saying \u201cCreate a pull request\u201d:</p> <p></p> <p>Please make sure the title and the description of your pull request are spell-checked and express the purpose of the changes in a simple and concise way. A good description will help yourself, the other contributors to ALICE software, and it will guarantee a faster approval (if required).</p> <p>Notice GitHub is a popular, public, hosting site, so there will be zero tolerance for offending statements or embarrassments to ALICE collaboration. In case of doubt, you can find more information in the commit guidelines.</p> <p></p> <p>Once you are done, your code is proposed for inclusion in the official repository, but it\u2019s not yet in, as it needs to pass a review process. Notice also that creating pull requests can be done from the command-line, see the advanced guide for more information.</p>"},{"location":"git-tutorial/#review-process","title":"Review process","text":"<p>Pull requests are checked for permissions first, and permissions are directory-based (or in some cases even file-based). We have retained the old permissions, so if you were not previously supposed to modify files under a certain directory, this process now requires an approval.</p> <p>There might be two possible scenarios:</p> <ul> <li>The user is allowed to modify all files affected by the pull request.</li> <li>The user is not allowed to modify all files and there is a list of   \u201capprovers\u201d who must approve it first.</li> </ul> <p>In the first case, the user is allowed to modify the files and the build system will tell you that by commenting. For example:</p> <p></p> <p>In the other case, if the user is not allowed to modify the code touched by the pull requests, the person(s) responsible will be contacted automatically and will be asked to comment on the pull request and whether or not the change is approved. In this example, Jan Fiete and Jochen need to approve the request:</p> <p></p> <p>Note that the system will add the real name next to the GitHub username. GitHub users are mentioned by prepending <code>@</code> to the username in a comment: by default, mentioned users will receive an email notification. This is how approvers get notified of pending commits.</p> <p>People with approval rights have now to comment by posting one of the following special comments:</p> <ul> <li><code>+1</code>: approve the change. If tests are successful the pull request   will be automatically merged.</li> <li><code>+test</code> approve testing only. Tests will be started but pull request   won\u2019t be automatically merged even if tests are all green. Green tests will   require a further approval.</li> </ul> <p>Note that the <code>+1</code> or <code>+test</code> must be the first word of your comment, otherwise the comment will be ignored. The automatic review system will provide feedback after your reply. Obviously, <code>+1</code>s from unauthorized users are simply ignored.</p> <p>Once all approvals have been granted, testing begins. The automatic system will give you a feedback similar to the following:</p> <p></p> <p>No pull request is automatically rejected. In case a pull request wants to change the project structure it will be handled by the project administrators.</p>"},{"location":"git-tutorial/#testing-process","title":"Testing process","text":"<p>Every single pull request is tested for a successful build on our production environment: this means that a pull request in AliPhysics should work with the reference AliRoot version using the same environment used on the Grid.</p> <p>The automatic build system provides you feedback through the GitHub testing interface. In case you see a yellow badge, it means that the system has taken over your request and it is now trying to build it:</p> <p></p> <p>If your code produces an error, this is reported together with the problem. For instance:</p> <p></p> <p>Part of the build log is reported in the comment. The full log is also available by clicking on the \u201cFull log\u201d link.</p> <p>In this case, you need to fix the problem and push the fix to your fork (the same way as before). The new commits are then automatically added to the pull request, and testing is restarted. If you don\u2019t want to add a commit but you simply want to change your previous one have a look at the amend howto below.</p> <p>If your code works fine, this will be reported:</p> <p></p> <p>Your code will be merged into the master and the pull request closed:</p> <p></p> <p>This may be a good moment to update your repository with the latest changes in the master.</p>"},{"location":"git-tutorial/#pull-request-size-limit","title":"Pull request size limit","text":"<p>We have put in place a size check on each opened pull request set to 20 MB. The limit is in place in order to avoid an uncontrolled growth of the Git repositories and make them slimmer and easier to download.</p> <p>In case you go beyond the limit, your pull request will be automatically rejected:</p> <p></p> <p>You will also receive an email notification. The general idea is to use the code repositories to store code only: since sometimes there is the need to store data files too we are providing an alternative with the following features:</p> <ul> <li>Large files are easy to upload and with proper PWG-based permissions</li> <li>Large files are versioned daily on CVMFS for easy access from Grid jobs</li> <li>We have an interface in AliRoot to access those files transparently</li> </ul> <p>If you are using or plan to use large files, even if you are below our current limit, we encourage you to follow the documented procedure.</p>"},{"location":"git-tutorial/#conflicts-between-different-pull-requests","title":"Conflicts between different pull requests","text":"<p>Sometimes it might happen that your pull request touches files modified also by other users, thus creating a \u201cconflict\u201d. Conflicts cannot be solved automatically: a human is needed to sort them out.</p> <p>Conflicts with pull requests can occur at any time.</p> <ul> <li>As soon as you open a pull request. This means that probably your code   did not have all the upstream changes when you have opened the pull request.</li> <li>After you have opened a pull request (even if tests were in progress   already!) This means that, while your pull request was being tested,   another one with incompatible changes got merged upstream.</li> </ul> <p>In both cases you will receive a notification in the form of a comment (which by default triggers an automatic email). For instance:</p> <p></p> <p>The GitHub interface suggests you to use the \u201cweb editor\u201d or the \u201ccommand line\u201d to resolve conflicts, and presents you with sensible suggestions. The web editor option is very convenient when conflicts are trivial (i.e. you have set <code>myPtCut = 12345</code> and your fellow colleague has set it to <code>myPtCut = 98765</code>: contact her to know who is right and fix the cut accordingly). To start the web assisted merging, click on \u201cresolve conflicts\u201d.  The following window shows you the conflicts one by one.</p> <p></p> <p>For each conflict you find the following snippets:</p> <pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; master\n  // code that is already in the master\n=========\n  // your code (of the current pull request)\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n</code></pre> <p>The code above is the existing code. The one below your change. Freely edit in the window until you think the conflict is resolved. Now you can save your changes by clicking \u201cmark as resolved\u201d.</p> <p></p> <p>Once all files have been processed, click on \u201ccommit changes\u201d:</p> <p></p> <p>The changes are saved as a new commit to your fork and automatically added to the pull request. Now the review and testing process starts from the beginning.</p> <p>For more complex conflict resolutions, or if you are uncomfortable with web interfaces, there is an extended tutorial here.</p>"},{"location":"git-tutorial/#amend-an-open-pull-request","title":"Amend an open pull request","text":"<p>In case the pull request is not approved or automatic tests do not pass, you should take the necessary measures to amend it. This is done by simply making changes to your local repository, commit them and push them: new commits will be automatically appended to the already opened pull request, and tests will be restarted.</p> <p>If you have a single broken commit with your changes and you want to change it (as opposed to adding a new commit with the fixes) you can commit with the command:</p> <pre><code>git commit --amend\n</code></pre> <p>This will require a <code>git push -f origin</code> afterwards. If you don\u2019t force-push it won\u2019t go through.</p>"},{"location":"git-tutorial/#discard-pull-request-including-changes-made-in-your-fork","title":"Discard pull request including changes made in your fork","text":"<p>In case you want to retire your pull request by throwing away your changes and resume your work from upstream you need to \u201creset\u201d the state of your working copy to the upstream repository:</p> <pre><code>cd ~/alice/AliPhysics\ngit branch my-backup-just-in-case  # create a branch backupping your state\ngit fetch --all\ngit reset --hard upstream/master\ngit push -f origin\n</code></pre> <p>Now, you have aligned your current branch with the upstream changes, and your former work was backupped just in case, in the <code>my-backup-just-in-case</code> branch (of course the name is arbitrary). The backup part is optional.</p> <p>Note that doing so without a backup will imply a loss of your current work. You must really be sure that you want to discard it first. If you want to work on multiple features at the same time, and have different pull requests open at once, please refer to the advanced guide.</p>"},{"location":"git-tutorial/#restore-work-from-a-backupped-branch","title":"Restore work from a backupped branch","text":"<p>If at some point you wish to resume your work from a previously abandoned branch (whose name we assume is <code>my-backup-just-in-case</code>), you can do from your master branch:</p> <pre><code>cd ~/alice/AliPhysics\ngit pull --rebase upstream master\ngit pull --rebase . my-backup-just-in-case\n</code></pre> <p>With the double <code>git pull</code> you are getting the new changes from upstream, and you are importing in your current branch your previously backed up work.</p>"},{"location":"git/","title":"Git","text":"<p>On March 22nd 2017, ALICE Offline Software moved its sources to be hosted on Github.</p> <p>You can find a basic tutorial on how to get started with AliRoot and AliPhysics on Github here and a more advanced tutorial to help you treat more complex usecases here.</p> <p>If you are completely new to git and Github, you can find more guides and tutorials on how to get started here.</p>"},{"location":"infrastructure-alibi-user-guide/","title":"AliBI Quickstart Guide","text":"<p>The Alice Benchmark Infrastructure is a service that was established to provide a platform for systematic, reproducible and consistent benchmarks for ALICE O2.</p> <p>Its primary task is to provide automated performance regression testing for simulation and reconstruction nightlies, however it is open to developers for their own benchmarking tasks within extended CERN working hours.</p>"},{"location":"infrastructure-alibi-user-guide/#hardware","title":"Hardware","text":"<p>For the sake of reproducible results, a physical server (compute node) has been acquired: * 2x Xeon Gold 6132 (2.6GHz, 14Core each) * 384GB ECC DDR4-2666 RAM * Nvidia Geforce RTX 2080 (8GB GDDR5) * AMD Radeon VII (16GB HBM II)</p>"},{"location":"infrastructure-alibi-user-guide/#software","title":"Software","text":"<ul> <li>latest version of Cern CentOS 7</li> <li>Full integration into CERN environment</li> <li>Users can exchange data via:<ul> <li>AFS</li> <li>EOS</li> <li>CVMFS</li> </ul> </li> <li>Large SSD scratch space for I/O critical tasks</li> <li>Docker </li> </ul>"},{"location":"infrastructure-alibi-user-guide/#getting-access","title":"Getting Access","text":"<p>Become member of e-group alibi-users</p>"},{"location":"infrastructure-alibi-user-guide/#working-with-the-alibi-service","title":"Working with the AliBI service","text":"<p>To avoid the interference of multiple users accessing the machine in parallel, users have to request exclusive access to the compute node by asking for an allocation via the SLURM workload manager.</p> <p>Allocations can be requested in two different work queues: * Short term interactive shell login directly on the compute node for at most 2h * Batch scripts (non-interactive) with a runtime of at most 10h.</p>"},{"location":"infrastructure-alibi-user-guide/#query-work-queues","title":"Query Work Queues","text":"<ul> <li>Login to <code>alibi.cern.ch</code></li> <li>The <code>sinfo</code> command will display the available work queues, their resources, time limits and the state  <pre><code>-bash-4.2$ sinfo\nPARTITION    AVAIL  TIMELIMIT  NODES  STATE NODELIST\ninteractive*    up    2:00:00      1  alloc alibicompute01.cern.ch\nbatch           up   10:00:00      1  alloc alibicompute01.cern.ch\n</code></pre> Note that both queues are processed by a single node: <code>alibicompute01.cern.ch</code>. As a consequence an active job from either queue will set the state of both queues to <code>alloc</code> and will block until the job is finished. Find out more about <code>sinfo</code> here</li> </ul>"},{"location":"infrastructure-alibi-user-guide/#query-for-jobs","title":"Query for Jobs","text":"<ul> <li>Login to <code>alibi.cern.ch</code></li> <li>The <code>squeue</code> command will display all of the request that have been submitted to one of the queues and are either currently running or pending <pre><code>-bash-4.2$ squeue \n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n               188     batch submit_s  swenzel  R    1:58:26      1 alibicompute01.cern.ch\n</code></pre> Find out more about <code>squeue</code> here here. There also is the graphical <code>sview</code> client which is documented here.</li> </ul>"},{"location":"infrastructure-alibi-user-guide/#requesting-an-interactive-shell-session","title":"Requesting an Interactive Shell Session","text":"<p>Users can request interactive shell sessions. This allows direct login to the compute node via <code>ssh</code> as long as the allocation is active.  * Login to <code>alibi.cern.ch</code> * Ask for interactive session <pre><code>salloc --time HH:MM:SS\n</code></pre> This will request a shell session in the <code>interactive</code> queue lasting as long as specified in <code>--time</code>. Requests of more than the queue limit of 2h will be rejected. Without the <code>--time</code> parameter session length defaults to 15min.</p> <pre><code>-bash-4.2$ salloc \nsalloc: Granted job allocation 192\nsalloc: Waiting for resource configuration\nsalloc: Nodes alibicompute01.cern.ch are ready for job\nallocation on partition interactive granted. Go and login into alibicompute01.cern.ch\nJobId=192 JobName=sh\n   UserId=milettri(101957) GroupId=def-cg(2766) MCS_label=N/A\n   Priority=4294901732 Nice=0 Account=(null) QOS=(null)\n   JobState=RUNNING Reason=None Dependency=(null)\n   Requeue=0 Restarts=0 BatchFlag=0 Reboot=0 ExitCode=0:0\n   RunTime=00:00:03 TimeLimit=00:15:00 TimeMin=N/A\n   SubmitTime=2020-02-10T15:04:34 EligibleTime=2020-02-10T15:04:34\n   AccrueTime=Unknown\n   StartTime=2020-02-10T15:04:34 EndTime=2020-02-10T15:19:34 Deadline=N/A\n   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2020-02-10T15:04:34\n   Partition=interactive AllocNode:Sid=alibilogin01.cern.ch:27480\n   ReqNodeList=(null) ExcNodeList=(null)\n   NodeList=alibicompute01.cern.ch\n   BatchHost=alibicompute01.cern.ch\n   NumNodes=1 NumCPUs=56 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:*\n   TRES=cpu=56,node=1,billing=56\n   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\n   MinCPUsNode=1 MinMemoryNode=0 MinTmpDiskNode=0\n   Features=(null) DelayBoot=00:00:00\n   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)\n   Command=(null)\n   WorkDir=/afs/cern.ch/user/m/milettri\n   Power=\n</code></pre> <p>Once your interactive allocation has been granted, you can <code>ssh</code> into the compute node and start using it. The session will be automatically closed if time runs out. <pre><code>bash-4.2$ salloc: Job 192 has exceeded its time limit and its allocation has been revoked.\n/bin/sh: line 1:  4309 Hangup                  $SHELL\n</code></pre></p> <p>Find out more about <code>salloc</code> here.</p>"},{"location":"infrastructure-alibi-user-guide/#submitting-a-batch-job","title":"Submitting a Batch Job","text":"<p>TBD</p>"},{"location":"infrastructure-alibi-user-guide/#faq","title":"FAQ","text":""},{"location":"infrastructure-alibi-user-guide/#which-local-directories-can-i-use-on-the-compute-node","title":"Which Local Directories Can I Use on The Compute Node?","text":"<p>Fast, local directories are available under <pre><code>$L_HOME=/home/$USER\n</code></pre> This is your local home directory. Data is kept and users will be asked to clean up this directory if we are about to run out of capacity <pre><code>$SCRATCH=/tmp/$USER\n</code></pre> This is a temporary directory which will be cleared out regularly without prior announcement</p>"},{"location":"infrastructure-alibi-user-guide/#can-i-use-ssh-keys","title":"Can I use SSH keys?","text":"<p>Yes but just as with <code>lxplus</code> you will get any Kerberos, AFS and eos token which will cause access issues including no access (neither read nor write) to your home directory</p>"},{"location":"infrastructure-alibi-user-guide/#i-cannot-readwrite-to-afs-or-eos","title":"I Cannot Read/Write to AFS or EOS","text":"<p>You probably logged in with a <code>ssh</code> key or your ssh is misconfigured.  To check the state of your Kerberos cache use <code>klist</code>. If it complains about an empty credentials cache: <pre><code>-bash-4.2$ klist\nklist: No credentials cache found (filename: /tmp/krb5cc_101957)\n</code></pre></p> <p>issue the following commands: * <code>kinit</code>: request/renew kerberos token * <code>aklog</code>: request/renew afs token * <code>eosfusebind</code>: sets up eos directories</p> <p>After this operation your kerberos cache should look like this  <pre><code>-bash-4.2$ klist\nTicket cache: FILE:/tmp/krb5cc_101957\nDefault principal: milettri@CERN.CH\n\nValid starting       Expires              Service principal\n06.02.2020 10:30:43  07.02.2020 11:30:38  krbtgt/CERN.CH@CERN.CH\n    renew until 11.02.2020 10:30:38\n06.02.2020 10:30:43  07.02.2020 11:30:38  afs/cern.ch@CERN.CH\n    renew until 11.02.2020 10:30:38\n</code></pre> and you should be able to access eos and afs directories.</p>"},{"location":"infrastructure-alibi/","title":"ALICE Benchmarking Infrastrure (AliBI)","text":"<p>The main goal of AliBI is to provide a service for benchmarking CPU and GPU code in a consistent, reproducible environment. This allows monitoring of performance of the code base over time, especially for simulation and reconstruction tasks.</p> <p>The system is conceived to run two types of jobs: * Nightly performance regression tests for simulation and reconstruction tasks * Interactive and batch access for registered users during CERN extended working hours.</p> <p>To ensure that results are always reproducible, the machine setup is enforced and controlled using Puppet and access to the compute resources is serialized using the SLURM cluster manager. This means that users do not login onto the nodes directly where the computation is being carried out. Instead, users log in into a head node and ask for access to compute resources. If they can be granted, an interactive bash session on a compute node is opened. In this session the following guarantees can be made: * The user is the only active user on the underlying hardware eliminating system load that might have otherwise been caused by other users.  * The system state corresponds to the one described in the systems initial puppet manifest. This ensures that no processes or containers from previous users are still running on the hardware as well as a consistent software stack.</p>"},{"location":"infrastructure-alibi/#installing-the-alibi-system","title":"Installing the AliBI system","text":"<p>The AliBI system relies on a CERN OpenStack VM for the head node (<code>alibilogin01.cern.ch</code>) and a bare metal server as compute node (<code>alibicompute01.cern.ch</code>). The software stack and machine state is formalized using puppet manifests and is fully integrated in the CERN configuration management ecosystem. The setup process is fully described below.</p>"},{"location":"infrastructure-alibi/#alibi-head-node","title":"AliBI head node","text":"<ul> <li>On <code>aiadm.cern.ch</code> enter the OpenStack Release Testing environment by running</li> </ul> <pre><code>eval $(ai-rc \"ALICE Release Testing\")\n</code></pre> <ul> <li>Spawn the head node by</li> </ul> <pre><code>ai-bs -g alibuild/alibi/login --foreman-environment alibuild_alibi --cc7 --nova-sshkey alibuild --nova-flavor m2.xlarge --landb-mainuser alice-agile-admin --landb-responsible alice-agile-admin alibilogin01\n</code></pre> <ul> <li>add alias to <code>alibi</code>:</li> </ul> <pre><code>openstack server set --property landb-alias=alibi alibilogin01\n</code></pre>"},{"location":"infrastructure-alibi/#alibi-compute-node","title":"AliBI compute node","text":"<p>The compute node is a physical machine outside the CERN datacenter, which makes provisioning a bit more complicated.</p>"},{"location":"infrastructure-alibi/#registrations-only-for-first-time-set-up","title":"Registrations (only for first time set up)","text":"<ul> <li>Register the machine in CERN LANDB</li> <li>Create an entry for the machine in Foreman:</li> <li>In Foreman, select <code>Hosts&gt;New Host</code>. </li> <li>In Host enter:<ul> <li>Name: <code>alibicompute01</code></li> <li>Host Group: <code>alibuild/alibi/compute</code></li> <li>Environment: <code>production</code></li> <li>Rest is blank</li> </ul> </li> <li>Puppet classes: blank</li> <li>Interfaces: en1 - crosscheck with LANDB!<ul> <li>Type: <code>Interface</code></li> <li>Mac address: <code>08:f1:ea:f0:1f:3c</code></li> <li>Device identifier: <code>eno1</code></li> <li>DNS name: <code>alibicompute01</code></li> <li>Domain: <code>cern.ch</code></li> <li>Subnet: <code>CERN GPN 2 (188.184.0.0/15)</code></li> <li>IP address: <code>188.184.2.54</code></li> <li>Managed: <code>YES</code></li> <li>Primary: <code>YES</code></li> <li>Provision: <code>YES</code></li> </ul> </li> <li>Operating System:<ul> <li>Architecture: <code>x86_64</code></li> <li>Operating System: <code>CentOS 7.7</code></li> <li>Media: <code>CentOS mirror</code></li> <li>Root password required.</li> </ul> </li> <li>Parameters: no changes.</li> <li>Additional Information:<ul> <li>Owned by: <code>alice-agile-admin</code></li> <li>Enabled: <code>YES</code></li> <li>Hardware Model: <code>ProLiant DL380 Gen10</code></li> </ul> </li> </ul>"},{"location":"infrastructure-alibi/#prepare-installation","title":"Prepare installation","text":"<ul> <li>Based on the Foreman entry, a provisioning template in form of a kickstart file is generated and is updated every time the configuration in Foreman is changed.</li> <li>Since the compute node is outside of the CERN datacenter it does not have direct access to this file, so it needs to be downloaded and self hosted for the duration of the installation.</li> <li>Download kikstart file from <code>Templates&gt;provision Template&gt;Review</code></li> <li>Inside the file:<ul> <li>Set install to <code>graphical</code></li> <li>Remove content about:</li> <li>bootloader (mbr)</li> <li>partitioning</li> </ul> </li> <li>Host the file on a webserver. The simplest way is to use python2.7 <code>python -m SimpleHTTPServer</code> in the directory where your kickstart file is located.</li> <li>Stage certificate on <code>aiadm.cern.ch</code>:</li> </ul> <pre><code>certmgr-stage --host alibicompute01.cern.ch\n</code></pre> <ul> <li>Set Foreman environment to <code>alibuild/alibi</code>.</li> </ul>"},{"location":"infrastructure-alibi/#installation","title":"Installation","text":"<ul> <li>Get IPMI/ILO access to the physical server</li> <li>Boot machine in network boot (PXE)</li> <li>Select OS and press E to edit.</li> <li>Modify the <code>linuxefi ...</code> line by deleting everything that comes after <code>ip=dhcp</code>and append the location of your kickstart script such that it reads</li> </ul> <pre><code>linuxefi (http)/aims/boot/&lt;YOUR_CC_VERSION_HERE&gt;/vmlinuz ip=dhcp ks=http://&lt;PATH_TO_KICKSTART_FILE&gt;\n</code></pre> <ul> <li><code>CTRL+x</code> to start</li> <li>A graphical installer will start.<ul> <li>All options but the partitioning are already preset, but can be changed manually.</li> <li>Perform partitioning:</li> </ul> </li> </ul> Mountpoint Space (GB) /boot 1.0 /boot/efi 0.2 / 500.0 /docker 1000.0 /home 7000.0 /tmp 14000.0 <ul> <li>Start the installation and let it finish. The machine will restart automatically.</li> <li>At this point you will notice that the <code>post installation</code> section of the installation has not been completed automatically. Since all commands are bash, it can be executed dully by copy&amp; paste or extracted and executed as a separate script.</li> <li>Afterwards the machine state should reflect the puppet manifests and can be fully monitored using the CERN Foreman infastruture.</li> </ul>"},{"location":"infrastructure-alibi/#installation-of-packages-via-puppet","title":"Installation of packages via puppet","text":"<ul> <li> <p>Packages are installed via puppet. The configuration / manifests is taken from a special <code>alibi</code> branch on a central git repository    PUPPET-HOSTGROUP.</p> </li> <li> <p>Upon updating the manifests, changes can be immediately applied through (as root)</p> </li> </ul> <pre><code>puppet agent -t -v\n</code></pre>"},{"location":"infrastructure-alibi/#troubleshooting","title":"Troubleshooting","text":""},{"location":"infrastructure-alibi/#symptom-no-allocations-can-be-made-node-stuck-in-drain-state","title":"Symptom: No allocations can be made, node stuck in \"drain\" state","text":"<p>In case <code>sinfo</code> shows:</p> <pre><code>PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST\ncompute*     up   infinite      1  drain alibicompute01.cern.ch\n</code></pre> <p>We need to undrain the node. </p> <ul> <li>Make sure you understand why the node is stuck, if necessary restart the node. </li> <li>As admin, reset the node state by</li> </ul> <pre><code>scontrol update nodename=alibicompute01.cern.ch state=idle\n</code></pre>"},{"location":"infrastructure-alienvobox/","title":"Setup an AliEn VOBOX","text":""},{"location":"infrastructure-alienvobox/#register-the-vobox","title":"Register the VOBOX","text":"<p>An AliEn VOBOX has first to be registered to the AliEn LDAP. AliEn administrators can do that with two pieces of information:</p> <ul> <li>the desired site name (e.g. <code>CERN_MYSITE</code>), the fully qualified host name</li> <li>of the VOBOX (e.g. <code>mysitevobox.cern.ch</code>)</li> </ul> <p>A site certificate and an associated private key will be created.</p>"},{"location":"infrastructure-alienvobox/#store-credentials-in-vault","title":"Store credentials in Vault","text":"<p>First create a policy:</p> <pre><code>echo 'path \"secret/alienvoboxes/mysitevobox/*\" { policy = \"read\" }' | ./vault policy-write mysitevobox -\n</code></pre> <p>This policy allows reading the content of all secrets under <code>secret/alienvoboxes/mysitevobox</code>. Now we create a token valid one week:</p> <pre><code>vault token-create -policy mysitevobox -ttl 168h\n</code></pre> <p>The token can be renewed using the <code>vault token-renew</code> command.</p> <p>When obtaining the certificate and key in PKCS12 format, export it in two PEM files. Certificate:</p> <pre><code>openssl pkcs12 -clcerts -nokeys -in ~/mysitevobox.p12 -out usercert.pem\n</code></pre> <p>Password-protected key:</p> <pre><code>openssl pkcs12 -nocerts -in ~/mysitevobox.p12 -out userkey_enc.pem\n</code></pre> <p>Now unprotect the key:</p> <pre><code>openssl rsa -in userkey_enc.pem -out userkey.pem\n</code></pre> <p>Save the certificate in Vault. We will use the following keys:</p> <ul> <li><code>secret/mysitevobox/host_cert</code></li> <li><code>secret/mysitevobox/host_privkey</code></li> </ul> <p>We can use the following command (and then paste the secret to stdin):</p> <pre><code>vault write secret/mysitevobox/host_cert value=\"`cat`\"\n</code></pre> <p>Alternatively we can read it from a file:</p> <pre><code>vault write secret/mysitevobox/host_cert value=@usercert.pem\n</code></pre>"},{"location":"infrastructure-alienvobox/#run-the-ansible-configuration","title":"Run the Ansible configuration","text":"<p>Our configuration is stored on Ansible. To run it, by limiting the run only to the AliEn VOBOXes, do - from the private configuration folder:</p> <pre><code>ansible-playbook site.yml -i inventory/ -e vault_token=&lt;valid_vault_token&gt; -l alienvoboxes\n</code></pre> <p>A valid Vault token must be provided: secrets are stored there and not in the configuration repository.</p>"},{"location":"infrastructure-auto-builds/","title":"Setting up automated release builds","text":"<p>This document describes how to automatically start build jobs for a project on Jenkins when a new release is tagged on GitHub.</p>"},{"location":"infrastructure-auto-builds/#set-up-the-github-workflow","title":"Set up the GitHub workflow","text":"<p>The build is started by the <code>.github/workflows/release.yml</code> file in the repository that should be built. This file requests a VM, installs Kerberos to authenticate with Jenkins, and then starts real build task there. Here is a template:</p> <pre><code>name: Release\n\non:\n  release:\n    types: [published]\n\njobs:\n  build_release:\n    runs-on: ubuntu-18.04\n    steps:\n    - name: Install Kerberos\n      run: |\n        sudo DEBIAN_FRONTEND=noninteractive apt-get install -y krb5-user\n        cat &lt;&lt; \\EOF &gt; krb5.conf\n        ${{ \"{{\" }}secrets.KRB5CONF}}\n        EOF\n        grep rdns krb5.conf\n        sudo mv -f krb5.conf /etc/krb5.conf\n\n    - name: Trigger release in jenkins\n      run: |\n        echo ${{ \"{{\" }}github.event.release.tag_name}} | grep -e \"prod-20[0-9][0-9][0-1][0-9]-[0-9][0-9]\"\n        echo ${{ \"{{\" }}secrets.JENKINS_BOT_PASS}} | kinit ${{ \"{{\" }}secrets.PRINCIPAL}}\n        curl -X POST -k --negotiate -u : ${{ \"{{\" }}secrets.API_URL}} -H 'Content-Type: application/x-www-form-urlencoded' -d 'PROJECT_TAG=${{ \"{{\" }}github.event.release.tag_name}}'\n        klist\n        kdestroy\n</code></pre>"},{"location":"infrastructure-auto-builds/#secrets","title":"Secrets","text":"<p>GitHub secrets can be referenced in the build configuration using <code>${{ \"{{\" }}secrets.SECRET_NAME}}</code> syntax. The template script above needs the following secrets set:</p> <ul> <li><code>KRB5CONF</code>: the system configuration file for Kerberos. The important thing   about this is the following setting: <code>[libdefaults] rdns = false</code></li> <li><code>PRINCIPAL</code> and <code>JENKINS_BOT_PASS</code>: the username and password of the Jenkins   build user</li> <li><code>API_URL</code>: a Jenkins URL that the Kerberos token should be sent to in order to   start the build</li> </ul> <p>It seems easiest to set a single Kerberos configuration, Jenkins username and password for every project, but the API URL differs for each project. The first three secrets are therefore organisation-wide on GitHub, while the last is repository-specific.</p>"},{"location":"infrastructure-auto-builds/#jenkins-job","title":"Jenkins job","text":"<p>The automatic build is triggered on Jenkins by the <code>curl</code> command in the template above. A separate Jenkins configuration must exist for each project to be built. This should take a single parameter (<code>PROJECT_TAG</code> in the template above) specifying the Git tag name or commit hash to build from. The project-specific Jenkins configuration then invokes the general build task, specifying project-specific values.</p>"},{"location":"infrastructure-cvmfs/","title":"CVMFS releases","text":"<p>ALICE software is compiled and published on CVMFS, for use on the Grid, Hyperloop and LEGO trains.</p>"},{"location":"infrastructure-cvmfs/#adding-a-new-architecture","title":"Adding a new architecture","text":"<p>If you want to start publishing software for a new architecture (e.g. <code>el9-x86_64</code>), you need to do the following.</p> <p>You can edit the contents of CVMFS by SSH'ing into cvmfs-alice.cern.ch, then running <code>sudo -iu cvalice</code> and starting a CVMFS transaction using <code>cvmfs_server transaction alice.cern.ch</code>.</p> <ol> <li>Make <code>/cvmfs/alice.cern.ch/bin/alienv</code> handle the new architecture.    The usual procedure is to send a pull request to change the copy in ali-bot.    This will run some tests on the changed script.    Once merged into ali-bot, then deploy manually by copying the file to its path in CVMFS.</li> <li>Add the new architecture to aliPublish.conf.    You will at least need to publish the <code>GCC-Toolchain</code> and <code>grid-base-packages</code> packages, in addition to any physics packages you want to make available (like <code>O2PDPSuite</code>).</li> <li>Create a <code>BASE/1.0</code> modulefile for the new architecture at <code>/cvmfs/alice.cern.ch/el9-x86_64/Modules/modulefiles/BASE/1.0</code>.    The easiest way to do this is to copy the modulefile from an existing architecture and adjust it as necessary.</li> <li>Create symlinks for GCC builds under <code>/cvmfs/alice.cern.ch/etc/toolchain/modulefiles/&lt;arch&gt;/Toolchain/</code>.    For this, you should run the publisher manually once (or wait for it to run via cron), so that GCC builds are available under <code>/cvmfs/alice.cern.ch/&lt;arch&gt;/Modules/modulefiles/GCC-Toolchain/</code>.    For each desired GCC version, add a symlink <code>/cvmfs/alice.cern.ch/etc/toolchain/modulefiles/&lt;arch&gt;/Toolchain/GCC-vX.Y.Z</code> pointing to <code>../../../../../&lt;arch&gt;/Modules/modulefiles/GCC-Toolchain/vX.Y.Z-N</code>.</li> <li>Create a <code>default</code> symlink for the <code>grid-base-packages</code> modulefile under <code>/cvmfs/alice.cern.ch/&lt;arch&gt;/Modules/modulefiles/grid-base-packages</code>.    If you've just built <code>grid-base-packages</code> for the first time for the new architecture, it'll be called <code>v1-1</code>, so run <code>ln -s v1-1 /cvmfs/alice.cern.ch/&lt;arch&gt;/Modules/modulefiles/grid-base-packages/default</code>.</li> </ol> <p>When you're done, commit your changes by running <code>cd</code> (so that your shell isn't keeping a CVMFS directory open), then running <code>cvmfs_server publish alice.cern.ch</code>.</p> <p>If you want to abort your changes, run <code>cvmfs_server abort</code> and confirm by typing <code>y</code> at the prompt instead.</p> <p>Remember to re-enable the publisher in the crontab, if you disabled it earlier.</p>"},{"location":"infrastructure-docker-packer/","title":"ALICE Docker images","text":"<p>Most of our CI Jobs running on Nomad are containerized via Docker to ensure reproducibility between builds.</p> <p>The docker image definitions are available in alisw/docks, and the CERN docker registry is https://registry.cern.ch/</p>"},{"location":"infrastructure-docker-packer/#rebuilding-a-docker-image","title":"Rebuilding a Docker image","text":"<p>If an image definition has changed, it must be rebuilt and pushed to the proper registry for Nomad to use it in new job allocations.</p>"},{"location":"infrastructure-docker-packer/#packer-defined-images","title":"Packer-defined images","text":"<p>Newer images have a <code>packer.json</code> file, which allows them to be built using Hashicorp packer</p> <p>There's a GitHub Action here that will rebuild and push the images for you.</p> <p>In case you prefer to do it manually:</p> <pre><code>brew install packer # &gt; 0.10.0\ncd &lt;image-name&gt;\npacker build packer.json\ndocker push registry.cern.ch/alisw/&lt;image-name&gt;\n</code></pre>"},{"location":"infrastructure-docker-packer/#dockerfile-defined-images","title":"Dockerfile-defined images","text":"<p>Older images without a <code>packer.json</code> can be built with:</p> <pre><code>docker build -t alisw/&lt;image-name&gt; &lt;image-name&gt;\n</code></pre>"},{"location":"infrastructure-docker-packer/#conventions","title":"Conventions","text":"<p>The CI uses an image named <code>&lt;arch&gt;-builder</code> where <code>&lt;arch&gt;</code> is the architecture of the image. The CI system will automatically select the correct image for a given architecture, so the image name must match the format exactly.</p> <p>The code to infer the image names is here</p>"},{"location":"infrastructure-docker-packer/#reverting-a-broken-image","title":"Reverting a broken image","text":"<p>Our registry keeps previously built images, in case a new release has an issue you can just re-tag the previous image as <code>latest</code>, and go back to a working state</p> <p>For example, these are the last builds for <code>slc9-gpu-builder</code>: slc9-gpu-builder artifacts-tab</p>"},{"location":"infrastructure-frontend/","title":"Build Infrastructure Frontend","text":""},{"location":"infrastructure-frontend/#frontend-setup","title":"Frontend setup","text":"<p>The ALICE build infrastructure is exposed via SSO.</p> <p>Due to limitations of the SSO protocol this happens via single machine which runs apache and does the reverse proxying to the actual service.</p> <p>The machine is setup in CERN/IT puppet + OpenStack facility in the hostgroup <code>alibuild/frontend</code>.</p>"},{"location":"infrastructure-frontend/#disaster-recovering","title":"Disaster recovering","text":""},{"location":"infrastructure-frontend/#starting-the-frontend","title":"Starting the frontend","text":"<p>The quick recipe to restart the frontend is:</p> <ul> <li>Login to <code>aiadm.cern.ch</code>.</li> <li> <p>Set up your OpenStack environment by doing:</p> <p>eval $(ai-rc \"ALICE Release Testing\")</p> </li> <li> <p>To spawn a machine you need to use the <code>ai-bs-vm</code> wrapper, which will take   care of provisioning the machine and putting it in Foreman, so that it will   receive from it the Puppet configuration:</p> <p>MACHINE_NAME= <p>ai-bs-vm -g alibuild/frontend                  \\            --cc7                                 \\            --nova-sshkey alibuild                \\            --nova-flavor m2.large                \\            --landb-mainuser alice-agile-admin    \\            --landb-responsible alice-agile-admin \\            $MACHINE_NAME - Once you have the frontend created, you also need to grant it read-only   permission to some CERN S3 bucket we use for storing logs. The policy for   it can be found in the ali-marathon   repository. The required policies are:</p> <li> <p><code>s3/alice-build-logs-policy.json</code></p> </li> <p>and they need to have the right Ip Address registered there.</p>"},{"location":"infrastructure-frontend/#enabling-disabling-one-host-in-the-load-balancing","title":"Enabling / disabling one host in the load balancing","text":"<p>Machines in the <code>alibuild/frontend</code> hostgroup participate in a load balanced DNS alias. In order to do so they must be in roger state <code>production</code>. To do so:</p> <pre><code>roger update --app_alarmed false --appstate production --message 'Fully operational' &lt;hostname&gt;\n</code></pre> <p>to do an intervention on them:</p> <pre><code>roger update --app_alarmed true --appstate intervention --message '&lt;Some log message&gt;' &lt;hostname&gt;\npuppet agent -t -v\n</code></pre> <p>You can check their load balanced score with:</p> <pre><code>/usr/local/sbin/lbclient -d TRACE\n</code></pre>"},{"location":"infrastructure-frontend/#cern-single-sign-on-sso-authentication","title":"CERN Single Sign-On (SSO) authentication","text":"<p>Some web applications use Apache's OIDC support to authenticate with CERN SSO. Apache then sets various <code>OIDC_CLAIM_*</code> headers on the forwarded requests.</p> <p>See also the CERN SSO documentation.</p>"},{"location":"infrastructure-frontend/#adding-a-new-application","title":"Adding a new application","text":"<p>Applications must be configured on the CERN SSO side through the Application Portal and on the ALICE side though our Puppet-generated Apache configuration, specifically the file <code>it-puppet-hostgroup-alibuild/data/hostgroup/alibuild/frontend.yaml</code>.</p> <ol> <li>Add the application on the Application Portal</li> <li>Configure the client ID of the application in <code>it-puppet-hostgroup-alibuild/data/hostgroup/alibuild/frontend.yaml</code>, using <code>oidc_client_id: &lt;client ID&gt;</code></li> <li>Store the generated client secret in Teigi as <code>&lt;app name&gt;-oidc-client-secret</code></li> <li>Generate an OIDC crypto passphrase, e.g. using <code>tr -dc '[:alnum:].+_-' &lt; /dev/urandom | head -c 24; echo</code> and save it in Teigi as <code>&lt;app name&gt;-oidc-crypto-passphrase</code></li> <li>Add an OIDC (not SAML) registration to the new application</li> <li>Make sure you use <code>https://&lt;app name&gt;.cern.ch/oidc-redirect</code> as the redirect URI. Apache intercepts the <code>/oidc-redirect</code> path.</li> <li>Optionally, configure any required roles, e.g. <code>alice-member</code>:</li> <li>Add this role as documented here and map any required e-groups (e.g. <code>alice-member</code>) to it</li> <li>Configure <code>oidc_require_role: &lt;role identifier&gt;</code> for the application in <code>it-puppet-hostgroup-alibuild/data/hostgroup/alibuild/frontend.yaml</code></li> </ol>"},{"location":"infrastructure-jenkins/","title":"Creating the Jenkins Master","text":"<p>In order to drive the Continuous Integration process the ALICE build infrastructure uses Jenkins. </p> <p>The Jenkins master is started by Nomad, on a machine which belongs to the <code>alibuild/mesos/slave/jenkins</code> hostgroup in CERN puppet, while slaves are declared using Nomad under <code>ci-jobs/jenkins-builder/</code>. The main advantage of this setup is that we can run slaves inside a Docker container, so that it can run e.g. CentOS 7 builds on Alma 9 hosts.</p> <p>Master nodes are configured through Puppet in the file:</p> <ul> <li>/code/manifests/alibuild/mesos/slave/jenkins.pp</li> </ul>"},{"location":"infrastructure-jenkins/#essential-operation-guides","title":"Essential Operation Guides:","text":"<ul> <li>Create the Jenkins</li> <li>Starting Jenkins</li> <li>Killing a stuck job</li> <li>Triggering builds programmatically</li> <li>Gotchas and issues</li> </ul>"},{"location":"infrastructure-jenkins/#create-the-jenkins-master-only-in-case-of-disaster-recovery","title":"Create the Jenkins master (only in case of disaster recovery!!!!)","text":"<p>The jenkins master is created on top of the usual OpenStack / Foreman infrastructure at CERN. This is because we want to be able to run Jenkins even if every other bit of the build infrastructure fails.</p> <p>Creation of the jenkins masters in CERN Foreman setup is described at http://cern.ch/config/nodes/createnode.html. The short recipe to create the machine, to do only in case of disaster is:</p> <ul> <li>Login to <code>aiadm.cern.ch</code>.</li> <li>Set up your OpenStack environment by doing:   <pre><code>eval $(ai-rc \"ALICE Release Testing\")\n</code></pre></li> <li>To spawn a machine you need to use the <code>ai-bs</code> wrapper, which will take   care of provisioning the machine and putting it in Foreman, so that it will   receive from it the Puppet configuration:   <pre><code>MACHINE_NAME=&lt;alijenkinsXX&gt;\n\nai-bs -g alibuild/mesos/slave/jenkins       \\\n      --alma9                               \\\n      --nova-sshkey alibuild                \\\n      --nova-flavor m2.large                \\\n      --landb-mainuser alice-agile-admin    \\\n      --landb-responsible alice-agile-admin \\\n      $MACHINE_NAME\n</code></pre></li> </ul>"},{"location":"infrastructure-jenkins/#starting-jenkins","title":"Starting Jenkins","text":"<p>While the machine on which Jenkins is run is provisioned by OpenStack, the actual Jenkins instance is managed by Nomad. The instance can be started with:</p> <pre><code>cd ci-jobs\nnomad job plan jenkins-master.nomad  # sanity check\nnomad job run jenkins-master.nomad   # actually deploy the job\n</code></pre> <p>You can then look at the logs in the Nomad GUI.</p>"},{"location":"infrastructure-jenkins/#killing-a-stuck-job","title":"Killing a stuck job","text":"<p>Sometimes Jenkins jobs (especially pipelines) remain stuck in some weird state and refuse to be killed by the GUI. When this happens, the last resort is to do the following:</p> <ul> <li>Go to \"Manage Jenkins\"</li> <li>Go to \"Script Console\"</li> <li> <p>Adapt the following script to your needs:</p> <p>def jobId = XYZ   def jobName = \"daily-builds/daily-aliphysics-test\"   def job = Jenkins.instance.getItemByFullName(jobName)   def task = job.getBuildByNumber(jobId)   task.doKill()</p> </li> </ul>"},{"location":"infrastructure-jenkins/#triggering-builds-programmatically","title":"Triggering builds programmatically","text":"<p>It's now possible to start new builds in a programmatic way. In order to do so you must have a valid kerberos token, and you must be able to execute the build from the web GUI. The step by step guide is:</p> <ul> <li>Get the token with <code>kinit</code>, use <code>klist</code> to verify you have one.</li> <li> <p>Given the name of the job in the GUI, <code>&lt;job&gt;</code>, you can trigger a build with:</p> <p>curl -k -X POST --negotiate -u : https://alijenkins.cern.ch/kerberos/job//build --data-urlencode json='{}' <li> <p>The parametrized job can be started with:</p> <p>curl -X POST -k --negotiate -u : https://alijenkins.cern.ch/kerberos/job//buildWithParameters -H 'Content-Type: application/x-www-form-urlencoded' -d '' <p>The <code>&lt;parameters&gt;</code> are formatted as in a URL: <code>&lt;name&gt;=&lt;value&gt;&amp;&lt;name2&gt;=&lt;value2&gt;</code>.</p>"},{"location":"infrastructure-jenkins/#creating-jenkins-agents-with-guaranteed-resources","title":"Creating Jenkins agents with guaranteed resources","text":"<p>This is the main way we deploy Jenkins builders. The advantage of fixed builders is that we are never in a situation where there is not enough space on the cluster by accident to run a Jenkins build.</p> <p>You can create dedicated Jenkins builders using Nomad.</p> <p>Similar to the setup for CI builders, Jenkins builders are defined as YAML files under <code>ci-jobs/jenkins-builder/</code>.</p> <p>They are normally configured using three keys:</p> <ul> <li><code>name</code>: a user-visible name, to keep builders apart. It's a good idea to mention the OS that the builder is running, e.g. <code>slc9-builder-1</code>.   Make this the same as the file name, sans the <code>.yaml</code> extension.</li> <li><code>docker_image</code>: the image to run the builder inside of.   Builds will run for this platform.   For example: <code>registry.cern.ch/alisw/slc9-builder:latest</code>.</li> <li><code>is_light</code>: a boolean; if true, enough resources are allocated to actually run a compilation.   \"Light\" builders are useful to have for non-compilation tasks; for instance, some Jenkins builds wait for approved PRs to be merged before starting the build; this only takes up a slot on a \"light\" builder to avoid wasting resources.</li> </ul> <p>Jenkins builders also need to be declared to Jenkins. To do this, go to https://alijenkins.cern.ch/computer &gt; \"New Node\" and create a new node. Assuming the architecture is <code>&lt;arch&gt;</code>, the node needs to be called (e.g. <code>&lt;arch&gt;-builder-&lt;X&gt;</code>) where <code>&lt;X&gt;</code> is incremental number. Valid <code>&lt;arch&gt;</code> values are e.g. <code>slc7</code>, <code>slc8</code>, <code>ubuntu2004</code>, etc. These mirror <code>aliBuild</code>'s idea of architectures.</p> <p>Click on the newly create agent and note down the associated secret. This needs to be stored in the <code>jenkins-builder</code> Vault secret. Click \"create a new version\", then add a new key at the bottom, named <code>&lt;name&gt;_node_secret</code> (where <code>&lt;name&gt;</code> is the one you gave it in the YAML file earlier). For the value, paste in the secret hexadecimal token you copied from Jenkins earlier. Save the updated secret.</p> <p>Finally, you can create the new agent with:</p> <pre><code>cd ci-jobs/jenkins-builder/\nlevant render -var-file &lt;name&gt;.yaml | nomad job validate -  # check syntax\nlevant render -var-file &lt;name&gt;.yaml | nomad job plan -      # make sure job can be scheduled\nlevant render -var-file &lt;name&gt;.yaml | nomad job run -       # actually run job\n</code></pre>"},{"location":"infrastructure-jenkins/#gotchas-and-issues","title":"Gotchas and issues:","text":"<ul> <li>On some systems, the CERN CA is not available by default. You can overcome this by either:</li> <li>Go to https://ca.cern.ch and install all the required CA certificates. In general this is what is needed on macOS.</li> <li> <p>Installing the <code>CERN-CA-certs</code> package.</p> </li> <li> <p>On some systems, kerberos gives a token for the actual backend name, rather than <code>aliaurora</code>. You can check that by doing klist and you will see <code>HTTP/alibuild-frontend01.cern.ch@CERN.CH</code>:</p> </li> </ul> <pre><code>Credentials cache: API:B7FC3DD4-738F-417E-B2FA-92B2CCA9590C\n        Principal: eulisse@CERN.CH\n\n  Issued                Expires               Principal\nAug 14 15:50:42 2019  Aug 15 01:50:42 2019  krbtgt/CERN.CH@CERN.CH\nAug 14 15:50:46 2019  Aug 15 01:50:42 2019  HTTP/alibuild-frontend01.cern.ch@CERN.CH\n</code></pre> <p>In order to fix this you will have to change your kerberos configuration, usually found in <code>/etc/krb5.conf</code>, and add <code>rdns = false</code> in the <code>[libdefaults]</code> stanza.</p>"},{"location":"infrastructure-known-tradeoffs/","title":"Known tradeoffs / build issues of the build infrastructure","text":"<p>This is a list of known issues or tradeoffs in our build infrastructure. We document them and try very hard to find a viable solution to all of them, however so far the solution seems to be unaffordable or has even worse drawbacks so we decided to simply live with them when they happen. Any contribution to improve the situation is welcome.</p>"},{"location":"infrastructure-known-tradeoffs/#pr-checking","title":"PR checking","text":""},{"location":"infrastructure-known-tradeoffs/#pr-checking-dies-due-to-external-services-eg-ccdb-being-down","title":"PR checking dies due to external services (e.g. CCDB) being down","text":"<p>Sometimes checks fail because external services are down. Dealing with them in a proper way would imply mocking the service, but:</p> <ul> <li>developers often do not know / have time to do proper mocking which is a very tedious process and can often only catch a very limited subset of the various failure modes.</li> <li>proper mocking is extremely time consuming because it needs to track the change in behaviour of the services very closely in order not to have the test validate a wrong (compared to production) behaviour.</li> </ul> <p>As a mitigation we run our test continuously, rebuilding broken tests when there is no pending ones.</p>"},{"location":"infrastructure-known-tradeoffs/#pr-checks-can-affect-each-other-even-if-unrelated","title":"PR checks can affect each other, even if unrelated","text":"<p>In order to save time, we check our tests in the same build area, so that we rebuild only changes between one build and another. Due to limitations in CMake or undetected missing dependencies, we can however end up in a state where a given test interferes with another, in particular:</p> <ul> <li>When libraries / dictionaries are moved around</li> <li>When a missing / implicit dependency is present and the order in which PRs are build in the PR checker is by chance a working one.</li> </ul>"},{"location":"infrastructure-known-tradeoffs/#pr-checks-introduce-relocation-issues-a-few-days-after-merging","title":"PR checks introduce relocation issues a few days after merging","text":"<p>In order to save time, PR checkers do their best to reuse pre-built tarballs which are downloaded from a central server. However by design this requires have packages fully relocatable in particular:</p> <ul> <li>They should not contain any absolute path</li> <li>If they do, the path must contain the package hash, so that the build tool / deployment script can relocate the tarball correctly.</li> <li>They must not cache any absolute path associated to their dependencies.</li> </ul> <p>Failing that the net result will be that a relocation issue will be present and will manifest itself  Rebuilding a PR twice in two different locations is deemed to expensive. Doing proper sandboxing requires changing the tools we have to something like Bazel.</p>"},{"location":"infrastructure-known-tradeoffs/#errors-appear-in-the-pr-checker-which-are-not-there-local-builds","title":"Errors appear in the PR checker which are not there local builds","text":"<p>Some of the recipes use environment variables (in particular <code>ALIBUILD_O2_TESTS</code>) to trigger different behaviors, e.g. increase the amount of testing being done and enable / disable special features. We should try to minimize their usage, however unfortunately they are still widely used.</p>"},{"location":"infrastructure-known-tradeoffs/#prs-take-long-to-complete-all-tests","title":"PRs take long to complete all tests","text":"<p>By construction you are limited by the longest path, and even if we try to minimize the amount of work done, one has to ultimately chose between minimizing false negatives and performance. Work is currently being done to reduce the unneeded tests in particular for the analysis. A proper solution for this would be to use a tool which imposes specifying all the hidden dependencies and takes advantage of that. However, this most likely means to move away from CMake and so far it was not considered a viable solution.</p>"},{"location":"infrastructure-known-tradeoffs/#rpm-generation","title":"RPM generation","text":""},{"location":"infrastructure-known-tradeoffs/#updatable-rpm-packages-have-conflicting-files","title":"Updatable RPM packages have conflicting files","text":"<p>Updatable RPMs are generate from the tarballs of the various packages which are also deployed in CVMFS. Those tarballs are built and installed in a separate per-package location, in order to allow multiple, coexisting installations. This means that conflicting files can be introduced without any previous warning at RPM generation time. The alternative, i.e. installing everything in a single location, would either move the problem to it's conjugate for CVMFS installation, or it would mean that what is installed in CVMFS is different from what is packaged in the updateable RPMs, duplicating CI and debugging issues.</p>"},{"location":"infrastructure-known-tradeoffs/#externals","title":"Externals","text":""},{"location":"infrastructure-known-tradeoffs/#old-own-version-of-externals","title":"Old / own version of externals","text":"<p>Sometimes the externals provided in alidist are either old, or provide a rebuild of a commonly available tool. In general this happens because we need to still support Run 2 Production requirements (including ROOT5 and XRootD3) and we prefer maintain a single set of tools, rather than split our configuration management.</p> <p>Mitigations for this are the defaults mechanism in aliBuild (including the new \"per-architecture defaults\") and the requirement selection mechanisms (<code>--disable</code>, <code>prefer_system</code>, architecture specific requirements) which aliBuild provides.</p>"},{"location":"infrastructure-logs/","title":"Build logs","text":"<p>Logs for the PRs are now copied on the CERN S3 object store. They are accessible either via the read only web interface at:</p> <p>https://ali-ci.cern.ch/alice-build-logs/</p> <p>which is an SSO protected url exposed by machines in the <code>alibuild/frontend</code> puppet hostgroup or via the <code>s3://alice-build-logs</code> endpoint, which provides read-write capabilities.</p> <p>For the SSO access you need to be an alice member, while for the S3 endpoint, you either need to be in the <code>alice-vm-admin</code> egroup.</p>"},{"location":"infrastructure-logs/#essential-operation-guides","title":"Essential operation guides","text":"<ul> <li>Creating the bucket</li> <li>Updating the policy</li> <li>Accessing the logs programmatically</li> </ul>"},{"location":"infrastructure-logs/#creating-the-bucket","title":"Creating the bucket","text":"<p>Creating the bucket should not be needed unless some disaster happens. The current instructions to do so are:</p> <ul> <li>Go to the openstack dashboard select \"Object Store &gt; Containers\" and add a new container.</li> <li>Create a set of ec2 credentials for that container, as explained on the CERN S3 pages.</li> <li>Make sure with CERN/IT that the <code>ali-bot</code> S3 local user is still available.</li> <li>Set the expiration policy on the bucket to 60 days (see instructions on the CERN S3 pages) .</li> <li>Set the access policy to the contents of <code>ali-marathon/s3/alice-build-logs-policy.json</code>.</li> <li>Verify that using the <code>ali-bot</code> access_key / secret_key you can write files.</li> </ul>"},{"location":"infrastructure-logs/#updating-the-policy","title":"Updating the policy","text":"<p>In case you need to update the S3 access permission policy, e.g. in case the frontend IP changes, you need to do so in <code>ali-marathon/s3/alice-build-logs-policy.json</code> and then apply it to the <code>s3://alice-build-logs</code></p> <p>You can verify that a given machine has access to the logs by doing:</p> <pre><code>curl alice-build-logs.s3.cern.ch/test.txt\n</code></pre> <p>If you get an actual reply, rather than permission denied, it means the machine can access the logs.</p>"},{"location":"infrastructure-logs/#accessing-the-logs-programmatically","title":"Accessing the logs programmatically","text":"<p>Accessing the logs programmatically can be done via any S3 enabled client, e.g. <code>s3cmd</code> (command line) or <code>boto3</code> (python). Ask usual suspects for the access key, secret. An example of how new logs can be pushed via <code>boto3</code> is at https://github.com/alisw/ali-bot/blob/master/report-pr-errors#L175-L194.</p>"},{"location":"infrastructure-machines/","title":"Machines underlying the build infrastructure","text":""},{"location":"infrastructure-machines/#cluster-architecture-description","title":"Cluster architecture description","text":"<p>The ALICE build infrastructure consists of two kinds of nodes: masters, responsible for scheduling jobs, and agents, responsible for executing jobs and services. They are in general provisioned using CERN Openstack Infrastructure and configured using the CERN Puppet / Foreman setup.</p> <p>Masters belong to the Puppet hostgroup <code>alibuild/mesos/master</code> while agents belong to <code>alibuild/mesos/slave</code>. The configuration of those hostgroups can be found in the <code>master</code> branch of the it-puppet-hostgroup-alibuild git repository, in particular in:</p> <ul> <li>/code/manifests/mesos/master.pp for the master.</li> <li>/code/manifests/mesos/slave.pp for the slaves.</li> </ul> <p>In order to be able to modify this configuration, and to create or deploy machines in those hostgroups, you will have to be part of the <code>alice-puppet</code> and <code>alice-agile-admin</code> hostgroups.</p> <p>We have in particular three masters, each running on a separate OpenStack availability zone. These work in a High Availability (HA) mode, which allows the ensemble to continue working correctly, even in the eventuality that one of the machines goes down. A diagram for the services running on the masters can be found below:</p> <p></p> <p>The masters run the following services:</p> <ul> <li> <p>The Nomad server:   Nomad is used to schedule and deploy jobs like CI builders and publishers automatically on the cluster.</p> </li> <li> <p>The Consul server:   A key-value store, used for its DNS features (Nomad jobs are assigned <code>&lt;job name&gt;.service.consul</code> domain names), and used as a backing store for Vault.</p> </li> <li> <p>The Vault server:   This service stores secrets and lets Nomad jobs use them, by substituting them into job declarations on-the-fly.</p> </li> <li> <p>Prometheus:   A monitoring service that polls various running jobs, in addition to the Nomad, Consul and Vault servers, and sends metrics to MONIT Cortex.   This integration is documented here.</p> </li> </ul>"},{"location":"infrastructure-machines/#essential-operation-guides","title":"Essential Operation Guides","text":"<ul> <li>Getting access to the OpenStack / Puppet infrastructure</li> <li>Creating a master</li> <li>Backup the masters</li> <li>Rebuild a master</li> <li>Creating an agent</li> <li>Reboot an agent</li> <li>Delete an agent</li> </ul>"},{"location":"infrastructure-machines/#getting-access-to-the-openstack-puppet-infrastructure","title":"Getting access to the OpenStack / Puppet infrastructure","text":"<p>First of all make sure you have all the rights to create machines in OpenStack and to administer them via Puppet. </p> <p>To get the OpenStack access rights, you should ask to become member of the <code>alice-vm-admin</code> egroup. To get the Puppet rights, you should ask to become member of the <code>alice-agile-admin</code> egroup. This can be done using the usual egroups interface.</p> <p>Once you have those rights to use OpenStack, you need to ssh into the CERN OpenStack administration machines (<code>aiadm.cern.ch</code>) and obtain the correct OpenStack credentials for the virtual machines by running:</p> <pre><code>eval $(ai-rc \"ALICE Release Testing\")\n</code></pre> <p>or, for the physical machines managed by CERN IT:</p> <pre><code>eval $(ai-rc \"ALICE Release Testing - physical nodes\")\n</code></pre> <p>You can now execute the various OpenStack commands, using the CLI tool called <code>openstack</code>. While an exhaustive list of all the available options can be obtained via <code>openstack help -h</code>, for the process of spawning new machines you probably only care about:</p> <ul> <li><code>openstack server list</code>: list the machines in the project you specified on the <code>eval $(ai-rc ...)</code> line above</li> <li><code>openstack image list</code>: list of OS images you can use. The build nodes should use the latest \"Alma 9\" ones.</li> <li><code>openstack flavor list</code>: list available flavors of virtual machines (i.e. how many CPUs, RAM).</li> </ul> <p>Further information on how CERN OpenStack cloud works can be found here.</p> <p>Note that you will have to login as <code>root</code> to all the machines.</p>"},{"location":"infrastructure-machines/#checklist-to-verify-the-status-of-a-master","title":"Checklist to verify the status of a master","text":"<p>In case there are issues with one of the masters you should follow the following checklist:</p> <ul> <li>Check on the Openstack Dashboard if the machine is up and running.</li> <li>Check in Foreman if there are any puppet errors.</li> <li>Ping the machine.</li> <li>SSH into the machine.</li> <li>Check if docker.service, nomad.service, consul.service and vault.service are running.</li> </ul>"},{"location":"infrastructure-machines/#creating-a-master","title":"Creating a master","text":"<p>Creation of masters in CERN Foreman setup is described in the Configuration Management User Guide. The short recipe for a build machine is:</p> <ul> <li>Login to <code>aiadm.cern.ch</code>.</li> <li>Set up your OpenStack environment by doing:</li> </ul> <p><pre><code>eval $(ai-rc \"ALICE Release Testing\")\n</code></pre> - To spawn a machine you need to use the <code>ai-bs</code> wrapper, which will take   care of provisioning the machine and putting it in Foreman, so that it will   receive from it the Puppet configuration:</p> <pre><code>MACHINE_NAME=&lt;alimesosXX&gt;\nZONE=cern-geneva-&lt;X&gt; # &lt;X&gt; needs to be in {a,b,c}\n                     # make sure you use different zones\n                     # to improve availability.\n\nai-bs -g alibuild/mesos/master               \\\n      --foreman-environment alibuild_devel   \\\n      --alma9                                \\\n      --nova-sshkey alibuild                 \\\n      --nova-availabilityzone $ZONE          \\\n      --nova-flavor m2.large                 \\\n      --landb-mainuser alice-agile-admin     \\\n      --landb-responsible alice-agile-admin  \\\n      $MACHINE_NAME\n</code></pre>"},{"location":"infrastructure-machines/#backup-master","title":"Backup master","text":"<p>Backing up of the masters is done for the <code>/build/consul</code> folder via the standard backup service of CERN/IT. The service itself is setup via puppet as usual. Things which can resuscitate a backup when it fails:</p> <pre><code># restarting the service\nservice dsmcad restart\n# Asking for an incremental backup\ndsmc incremental\n</code></pre>"},{"location":"infrastructure-machines/#creating-an-agent","title":"Creating an agent","text":"<p>Creation of mesos agents in CERN Foreman setup is described in the Configuration Management User Guide. The short recipe for a build machine is:</p> <ul> <li>Login to <code>aiadm.cern.ch</code>.</li> <li>Set up your OpenStack environment by doing (for build machines):</li> </ul> <pre><code>eval $(ai-rc \"ALICE Release Testing\")\n</code></pre> <p>or, for the physical/bare-metal machines:</p> <pre><code>eval $(ai-rc \"ALICE Release Testing - physical nodes\")\n</code></pre> <ul> <li>In order to create new machines, you will also need the public SSH key to be   added on the <code>alibuild</code> machines. Execute (assuming you have saved the public   SSH key in <code>alibuild.pub</code>):</li> </ul> <pre><code>openstack keypair create --public-key alibuild.pub alibuild\n</code></pre> <p>This only needs to be done the first time you create a VM.</p> <ul> <li>Specify a few parameters for the machine you want to spawn:</li> </ul> <pre><code>MACHINE_NAME=&lt;alibuildXX/alimetalXX&gt;\nFLAVOR=&lt;OpenStack flavor name, see below&gt;\nVOLSIZE=&lt;\"1000GB\" for VMs, empty for physical machines&gt;\n</code></pre> <p>For virtual machines, <code>FLAVOR</code> is <code>m2.2xlarge</code>. For physical/bare-metal   machines, this will be a string given by CERN IT, probably of the form   <code>p1.dlXXXXXXX.S513-V-IPXX</code>. You can list the flavors you have access to by   running <code>openstack flavor list</code>.</p> <ul> <li>To spawn a machine you need to use the <code>ai-bs</code> wrapper, which will take   care of provisioning the machine and putting it in Foreman, so that it will   receive from it the Puppet configuration:</li> </ul> <pre><code>ai-bs -g alibuild/mesos/slave --alma9                              \\\n      --foreman-environment production                             \\\n      --nova-sshkey alibuild --nova-flavor \"$FLAVOR\"               \\\n      --landb-mainuser alice-agile-admin                           \\\n      --landb-responsible alice-agile-admin                        \\\n      ${VOLSIZE:+--nova-attach-new-volume \"vdb=$VOLSIZE:type=io1\"} \\\n      \"$MACHINE_NAME\"\n</code></pre> <p>This will spawn a new machine. You can check the boot status either in the   OpenStack GUI or via <code>openstack server show -f yaml \"$MACHINE_NAME\"</code>. Of   course you should change the name of the machine (<code>&lt;alibuildXX&gt;</code> in the   example).</p> <p>For bare-metal machines in particular, a flavor being listed in <code>openstack   flavor list</code> does not guarantee that there is capacity for more hosts within   it. If you create a host and it is immediately in an \"ERROR\" state, try   another flavor or contact CERN IT.</p> <ul> <li>Machines may require a manual reboot to apply updates to the kernel command   line.</li> </ul> <p>In particular, make sure that <code>/proc/cmdline</code> contains   <code>systemd.unified_cgroup_hierarchy=0</code>. If not, reboot the machine.</p> <p>In order to make sure that the machine is correctly up and running, you should:</p> <ul> <li>ping it</li> <li>ssh to it</li> <li>run <code>puppet agent -t -v</code> until no errors are reported</li> <li>execute e.g. <code>docker pull registry.cern.ch/alisw/slc9-builder</code> to   force-pull the builder image.</li> </ul>"},{"location":"infrastructure-machines/#rebuilding-a-master","title":"Rebuilding a master","text":"<p>Rebuilding a master is a potentially disruptive operation, since our mesos setup requires at least 2 masters to be up and running in order to schedule new jobs. Therefore before you actually decide to rebuild one you should:</p> <ul> <li>Discuss with your collegueas whether that's a good idea.</li> <li>Make sure that the other two masters are properly functioning.</li> <li>If the master is the currently leading master, force a leadership transition to one of the other   two machines before the rebuild (Optional, since failower will take care of that).</li> </ul> <p>In order to perform the rebuild you need to do:</p> <ul> <li>Login to <code>aiadm.cern.ch</code>.</li> <li>Set up your OpenStack environment by doing:</li> </ul> <pre><code>eval $(ai-rc \"ALICE Release Testing\")\n</code></pre> <ul> <li>Actually rebuild the machine</li> </ul> <pre><code>ai-rebuild --alma9 alimesosXX\n</code></pre> <p>It can take up to one hour for the process to complete.</p> <ul> <li>In order to make sure that the machine is correctly up and running, you should:</li> <li>ping it</li> <li>ssh to it</li> <li>run <code>puppet agent -t -v</code> until no errors are reported</li> </ul>"},{"location":"infrastructure-machines/#rebuilding-an-agent","title":"Rebuilding an agent","text":"<p>Rebuilding an agent is potentially a problem, since the Nomad agent might be doing something, e.g. building a release, which should not be in general interrupted. Therefore you need to:</p> <ul> <li>Discuss with your collegueas whether that's a good idea.</li> <li>Verify that the machine is not running any particularly important task, by looking at the report   in the Nomad GUI. If in doubt, ask.</li> </ul> <p>In order to perform the rebuild you need to do:</p> <ul> <li>Login to <code>aiadm.cern.ch</code>.</li> <li>Set up your OpenStack environment by doing (for build machines):</li> </ul> <pre><code>eval $(ai-rc \"ALICE Release Testing\")\n</code></pre> <p>or, for the physical machines:</p> <pre><code>eval $(ai-rc \"ALICE Release Testing - physical nodes\")\n</code></pre> <p>depending on which project the machine belongs to.</p> <ul> <li>Actually rebuild the machine</li> </ul> <pre><code>ai-rebuild --alma9 alibuildXX\n</code></pre> <ul> <li>In order to make sure that the machine is correctly up and running, you should:</li> <li>ping it</li> <li>ssh to it</li> <li>run <code>puppet agent -t -v</code> until no errors are reported. If you keep having errors after a few     runs, report them.</li> </ul>"},{"location":"infrastructure-machines/#deleting-a-build-infrastructure-vm","title":"Deleting a build infrastructure VM","text":"<p>Documentation to delete a VM is found in the Configuration Management User Guide.</p> <p>The recipe for destoying agents is:</p> <ul> <li>Ask yourself why you are deleting the VM. Do it only if you want to get rid of it for good.    If you want to recreate it immediately after, e.g. to handle some    irreversible fault on the installation, you might first want to   try rebuilding it, since it will be much faster. </li> <li>Login to <code>aiadm.cern.ch</code>.</li> <li>Set up your OpenStack environment by doing:</li> </ul> <p><pre><code>eval $(ai-rc \"ALICE Release Testing\")\n</code></pre> - Delete the VM with <code>ai-kill &lt;alibuildXX&gt;</code> - Delete the previously attached volumes.</p>"},{"location":"infrastructure-machines/#rebooting-a-server","title":"Rebooting a server","text":"<p>In case there is an issue with any of the agents, a hard reboot can be attempted to bring it back to a working state. This can be done via the OpenStack GUI, in the Instances tab, or doing:</p> <ul> <li>Login to <code>aiadm.cern.ch</code>.</li> <li>Set up your OpenStack environment by doing:</li> </ul> <p><pre><code>eval $(ai-rc \"ALICE Release Testing\")\n</code></pre> - Actually reboot <code>&lt;server name&gt;</code></p> <pre><code>openstack server reboot --hard &lt;server name&gt;\n</code></pre> <p>in case the GUI is not functional.</p>"},{"location":"infrastructure-machines/#master-backups","title":"Master backups","text":"<p>Backup of the Consul server is done via CERN TSM. This needs to be renewed regularly and CERN IT will ping by email about it. Agents are not backed up.</p>"},{"location":"infrastructure-macos/","title":"CI builders on macOS","text":"<p>The macOS build infrastructure works the same way as its Linux counterpart -- it uses Nomad.</p> <p>This guide covers:</p> <ul> <li>Installation and initial setup of the machine</li> <li>Adding a CI checker</li> </ul>"},{"location":"infrastructure-macos/#installation-and-initial-setup","title":"Installation and initial setup","text":"<p>These are the instructions for macOS Ventura.</p> <ul> <li>During setup, create a user account for the <code>alibuild</code> user, do not sign in to iCloud.</li> <li>Sign into the App Store as <code>ali.bot@cern.ch</code>.</li> </ul> <p>Some commands below should be run on your local machine. These may refer to the new Mac's hostname, so set a variable for this now, or substitute <code>$newhost</code> manually in the commands below. <pre><code>newhost='&lt;short hostname of the new Mac, e.g. alibuildmac09&gt;'\n</code></pre></p>"},{"location":"infrastructure-macos/#set-up-firewall-exceptions","title":"Set up firewall exceptions","text":"<p>Add the new Mac's hostname to the list of non-Puppetized CI hosts in Puppet. You have to do this in two places, once each in the header of:</p> <ul> <li><code>it-puppet-hostgroup-alibuild/code/manifests/mesos/master.pp</code></li> <li><code>it-puppet-hostgroup-alibuild/code/manifests/mesos/slave.pp</code></li> </ul>"},{"location":"infrastructure-macos/#set-up-the-macs-network-connection","title":"Set up the Mac's network connection","text":"<p>On the Mac, go to System Settings -&gt; Network and disable WiFi.</p> <p>Then, in the network settings, go to Ethernet -&gt; Details -&gt; DNS, and click \"+\" under \"DNS Servers\" to add the IPv4 addresses of alimesos01, alimesos02 and alimesos03 as DNS servers. Remove other DNS servers (including the automatic CERN central ones).</p> <p>You will have to register them in LanDB too, the network will redirect you to the right page automatically.</p>"},{"location":"infrastructure-macos/#set-up-the-macs-hostname","title":"Set up the Mac's hostname","text":"<p>Make sure the Mac knows itself by it's real hostname, as it can have issues with DNS resolution otherwise. You can do this by going to System Preferences -&gt; General -&gt; About, and changing the computer name to the short hostname of the Mac (e.g. <code>alibuildmac09</code>).</p>"},{"location":"infrastructure-macos/#enable-ssh-and-vnc","title":"Enable SSH and VNC","text":"<p>To start both the SSH and VNC servers, enable remote login in System Preferences -&gt; General -&gt; Sharing -&gt; Remote Login, and Screen Sharing.</p> <p>Additionally, you may want to add the proper SSH keys to the <code>alibuild</code> user's <code>authorized_keys</code> file.</p>"},{"location":"infrastructure-macos/#prevent-the-mac-from-going-to-sleep","title":"Prevent the Mac from going to sleep","text":"<p>By default, Macs will go into a low-power state after a while without interactive use, which interrupts the CI build process. To prevent this, change the following settings in System Settings:</p> <p>In Energy, enable \"Start up automatically after a power failure\", \"Wake for network access\", and \"Prevent computer from sleeping automatically when the display is off\".</p> <p>In Lock Screen, set both \"Start Screen Saver when inactive\" and \"Turn display off when inactive\" to \"Never\".</p>"},{"location":"infrastructure-macos/#disable-crash-reporting","title":"Disable crash reporting","text":"<p>Some jobs are intended to crash, and we don't want the Mac to get stuck waiting for user input.</p> <pre><code>launchctl unload -w /System/Library/LaunchAgents/com.apple.ReportCrash.plist\nsudo launchctl unload -w /System/Library/LaunchDaemons/com.apple.ReportCrash.Root.plist\n</code></pre>"},{"location":"infrastructure-macos/#software-prerequisites","title":"Software prerequisites","text":"<ul> <li>Install the right version of XCode, either from the App Store or from xcodereleases.com.   Usually this should be the latest one from the App Store, but occasionally we don't support the latest one yet.   In that case, use the latest supported one.</li> <li>Open XCode in order to install the command line tools and accept the license, or run:   <pre><code>sudo xcode-select --install\nsudo xcodebuild -license\n</code></pre></li> <li>Install Homebrew using the instructions on their webpage:   <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\necho 'eval \"$(/opt/homebrew/bin/brew shellenv)\"' &gt;&gt; ~/.zprofile\n</code></pre>   ...and reload the session or <code>source ~/.zprofile</code>.</li> <li>Check if everything is OK via:   <pre><code>brew doctor\n</code></pre></li> <li>Install the software prerequisites:   <pre><code>brew install alisw/system-deps/alice-build-machine\n</code></pre></li> </ul>"},{"location":"infrastructure-macos/#create-a-build-volume","title":"Create a build volume","text":"<p>Open \"Disk Utility\". Select \"Macintosh HD\", then in the window title bar, press \"+\" above \"Volume\". Call the new volume <code>build</code> with format \"APFS\".</p>"},{"location":"infrastructure-macos/#create-the-work-environment","title":"Create the work environment","text":"<p>With recent MacOS versions, <code>/</code> is not writable. We install under <code>/opt/build</code> instead: <pre><code>sudo ln -s ../Volumes/build /opt/build\nsudo mkdir /opt/build/alice-ci-workdir\nsudo chown alibuild:staff /opt/build/alice-ci-workdir\n</code></pre></p> <p>Afterwards exclude the <code>/opt/build</code> directory from Spotlight in the system preferences. In System Preferences, go to Siri &amp; Spotlight -&gt; Spotlight Privacy (at the bottom of the page). In the \"Privacy\" tab, hit the \"+\" button. Now select the <code>build</code> volume and confirm.</p>"},{"location":"infrastructure-macos/#copy-grid-ca-certificates-from-another-host","title":"Copy Grid CA certificates from another host","text":"<p>O2 unit tests need this to connect to services like the test CCDB instance.</p> <p>On your local computer, run: <pre><code>ssh alibuildmac00.cern.ch tar -cz /etc/grid-security/certificates | ssh \"$newhost\" 'cat &gt; certs.tar.gz'\n</code></pre></p> <p>Then, on the Mac being set up, run: <pre><code>sudo mkdir -p /etc/grid-security/certificates\nsudo tar -xzf ~/certs.tar.gz --strip-components=3 -C /etc/grid-security/certificates\n</code></pre></p>"},{"location":"infrastructure-macos/#get-a-grid-host-certificate","title":"Get a Grid host certificate","text":"<p>O2 unit tests need this to connect to services like the test CCDB instance.</p> <p>At https://ca.cern.ch/ca/, request a new Grid host certificate for the machine. Make sure that reminders about expiring certs go to the responsible group, not just you. In order to do this, you must be listed as the \"responsible\" or \"main user\" of the machine in LanDB.</p> <p>Create the certificate request using the system OpenSSL. On your local machine, set up the environment:</p> <pre><code>TARGET_MACHINE=alibuildmacXX\nREMOTE_WORK_DIR=/Users/alibuild/renew-certificate\n</code></pre> <p>Open the page where you can paste the certificate request: </p> <pre><code>open https://ca.cern.ch/ca/host/Submit.aspx?template=ee2host&amp;instructions=openssl&amp;subject=$TARGET_MACHINE.cern.ch\n</code></pre> <p>Get in your clipboard the certificate request:</p> <pre><code>rm -fr $HOME/Downloads/host.cert\nssh $TARGET_MACHINE mkdir -p $REMOTE_WORK_DIR\nssh $TARGET_MACHINE cp /System/Library/OpenSSL/openssl.cnf $REMOTE_WORK_DIR/openssl.cnf\ncat &lt;&lt;EOF | ssh $TARGET_MACHINE \"cat &gt;&gt;$REMOTE_WORK_DIR/openssl.cnf\"\n[req]\nreq_extensions = v3_req\n\n[ v3_req ]\nbasicConstraints = CA:FALSE\nkeyUsage = nonRepudiation, digitalSignature, keyEncipherment\nsubjectAltName = @alt_names\n\n[alt_names]\nDNS.1 = $TARGET_MACHINE.cern.ch\nEOF\nssh $TARGET_MACHINE openssl req -new -subj \"/CN=$TARGET_MACHINE.cern.ch\" -out $REMOTE_WORK_DIR/newcsr.csr -keyout $REMOTE_WORK_DIR/privkey.pem -nodes -sha512 -newkey rsa:2048 -config $REMOTE_WORK_DIR/openssl.cnf\nssh $TARGET_MACHINE cat $REMOTE_WORK_DIR/newcsr.csr | pbcopy\n</code></pre> <p>Then paste it to generate the certificates. Download the base 64 certificate and copy it to the target machine with:</p> <pre><code>NEW_CERT=$HOME/Downloads/host.cert\nscp $NEW_CERT $TARGET_MACHINE:$REMOTE_WORK_DIR/host.cert\n# FIXME: linux users feel free to provide a PR using \"pass\"\nsecurity find-generic-password -a 'alibuild' -s \"$TARGET_MACHINE\" -w | ssh $TARGET_MACHINE sudo -S install -m 0600 -o alibuild -g staff $REMOTE_WORK_DIR/host.cert /etc/grid-security/hostcert.pem\nsecurity find-generic-password -a 'alibuild' -s \"$TARGET_MACHINE\" -w | ssh $TARGET_MACHINE sudo -S install -m 0600 -o alibuild -g staff $REMOTE_WORK_DIR/privkey.pem /etc/grid-security/hostkey.pem\n</code></pre> <p>Test that everything works correctly with (might need some adjustments to the path). On the <code>$TARGET_MACHINE</code>:</p> <pre><code>ssh $TARGET_MACHINE\n# Adapt to find a valid xjalienfs\nexport WORK_DIR=/Volumes/build/alice-ci-workdir/o2/sw\nsource \"$WORK_DIR/osx*/xjalienfs/latest/etc/profile.d/init.sh\"\nX509_USER_CERT=/etc/grid-security/hostcert.pem X509_USER_KEY=/etc/grid-security/hostkey.pem alien-token-init\n</code></pre> <p>Nomad does not apparently handle the change of certificate gracefully as of 1.6.2, so you need to restart it:</p> <pre><code>security find-generic-password -a 'alibuild' -s \"$TARGET_MACHINE\" -w | ssh $TARGET_MACHINE sudo -S brew service stop nomad\nsecurity find-generic-password -a 'alibuild' -s \"$TARGET_MACHINE\" -w | ssh $TARGET_MACHINE sudo -S sudo brew services start nomad --file=$HOME/homebrew.mxcl.nomad.plist\n</code></pre> <p>Finally clean-up the temporary area with:</p> <pre><code># We keep it explicit to avoid having REMOTE_WORK_DIR empty or pointing to some wrong place.\n# Check this is actually what you want to do!\nssh $TARGET_MACHINE rm -rf /Users/alibuild/renew-certificate\nrm -fr $HOME/Downloads/host.cert\n</code></pre>"},{"location":"infrastructure-macos/#ask-for-alien-access","title":"Ask for AliEn access","text":"<p>Ask Costin or Max to add the DN of the certificate you just installed to the list of allowed certs for the <code>alienci</code> user. You can get the certificate's DN using: <pre><code>openssl x509 -in /etc/grid-security/hostcert.pem -noout -text | grep Subject:\n</code></pre></p>"},{"location":"infrastructure-macos/#set-up-nomad-and-consul","title":"Set up Nomad and Consul","text":"<pre><code>sudo mkdir -p \"$(brew --prefix)/etc\"/{nomad,consul}.d\n</code></pre> <p>Then, copy <code>nomad.hcl</code> and <code>consul.hcl</code> into these directories from another CI Mac. Fix the permissions, since the files contain secrets: <pre><code>sudo chown root:admin \"$(brew --prefix)/etc\"/{nomad,consul}.d/*.hcl\nsudo chmod 600 \"$(brew --prefix)/etc\"/{nomad,consul}.d/*.hcl\n</code></pre></p> <p>Now adapt the files to the local host:</p> <ul> <li>In <code>consul.hcl</code>, change <code>advertise_addr</code> to the host's external IP address.</li> <li>In <code>nomad.hcl</code>, change <code>bind_addr</code> to the host's external IP address.</li> <li>In <code>nomad.hcl</code>, change <code>cpu_total_compute</code>, since Nomad doesn't know how to compute this itself for M1/M2 machines.   To compute the right number, run <code>sudo powermetrics -s cpu_power -n 1</code> and add up the maximum frequency (in MHz) for each listed CPU.</li> </ul> <p>You also need to set up custom launchd services for Nomad and Consul, since the ones packaged by Homebrew are not suitable for production use. On your local machine, run the following to copy the files into place: <pre><code>scp -3 alibuildmac00.cern.ch:{homebrew.mxcl.{nomad,consul}.plist,restart-services.sh} \"$newhost:.\"\n</code></pre></p> <p>Start the services by running the following command on the Mac: <pre><code>sudo ~/restart-services.sh\n</code></pre></p> <p>Finally, make sure that Nomad's work directory is readable by all users. This is necessary to run CI jobs as the <code>alibuild</code> user, since it cannot find the script otherwise: <pre><code>sudo chmod go+rx /opt/build/nomad\n</code></pre></p> <p>The host should appear in the list of Nomad clients. If it does not, check the log, e.g. using <code>less -RSM \"$(brew --prefix)/var/log/nomad.log\"</code>. If Nomad complains about not being able to connect to the master nodes at <code>alimesosNN.cern.ch</code>, update their firewall rules using: <pre><code>pdsh -w 'alimesos[01-03].cern.ch' puppet agent -tv\n</code></pre></p>"},{"location":"infrastructure-macos/#adding-a-ci-checker","title":"Adding a CI checker","text":""},{"location":"infrastructure-macos/#adding-a-nomad-job","title":"Adding a Nomad job","text":"<p>The Macs are configured on a host-by-host basis, unlike the Linux checkers, so that we can more tightly control what checks run where. This saves precious disks space, since many Macs lack this resource compared to the Linux machines.</p> <p>In the private <code>ci-jobs</code> repository, configure a new CI job variation by creating a file called <code>ci-jobs/ci/$newhost.yaml</code> with the following content (substituting the parts in <code>&lt;&gt;</code>): <pre><code>---\nrole: macos\narch: &lt;new hostname&gt;\nconfig_suffix: ''\nnum_builders: 1\n# Specify the total resources available on the host, so that we can reserve the\n# entire thing. This makes nomad's statistics more accurate.\nresources:\n  cpu: &lt;the number you configured earlier as cpu_total_compute&gt;\n  memory: &lt;total MB of memory available on the host&gt;\n</code></pre></p> <p>Once that's done, actually run the CI job on the new host:</p> <pre><code>cd ci-jobs/ci\nlevant render -var-file \"$newhost.yaml\" | nomad job plan -\n# If the above succeeds, then:\nlevant render -var-file \"$newhost.yaml\" | nomad job run -\n</code></pre>"},{"location":"infrastructure-macos/#configuring-individual-checks","title":"Configuring individual checks","text":"<p>Mac CI checkers are configured like their Linux equivalents, using <code>.env</code> files under <code>ali-bot/ci/repo-config/</code>. The Macs specifically are listed under <code>ali-bot/ci/repo-config/macos/</code>.</p> <p>Each host has a directory there named after its short hostname; it will run checks for the <code>.env</code> files inside its directory.</p> <p>If checks are not picked up, make sure the hostname matches what the Mac thinks it is. If in doubt, run <code>hostname -s</code> to check.</p>"},{"location":"infrastructure-macos/#notable-macos-post-mortes","title":"Notable macOS post-mortes","text":"<ul> <li>Issues after a powercut</li> </ul>"},{"location":"infrastructure-macos/#troubleshooting","title":"Troubleshooting","text":""},{"location":"infrastructure-macos/#nomad-service-doesnt-start-after-reboot-job-allocation-stuck-in-pending","title":"Nomad service doesn't start after reboot / Job allocation stuck in pending","text":"<p>Some machines aren't able to remount the disks properly after a reboot. You can usually fix this issue with the following commands:</p> <pre><code>sudo mkdir /Volumes/build\ndiskutil list # find the right disk for the next command\nsudo mount -t hfs /dev/disk2s1 /Volumes/build\nsudo /Users/alibuild/restart-services.sh\n</code></pre>"},{"location":"infrastructure-macos/#macs-continuously-running-out-of-memory","title":"Macs continuously running out of memory","text":"<p>Make sure the Crash Reporter is disabled, as it can cause jobs like <code>o2-framework-crashing-workflow</code> to hang indefinitely.</p>"},{"location":"infrastructure-macos/#nomad-cannot-stream-logs-path-escapes-the-alloc-directory","title":"Nomad cannot stream logs (Path escapes the alloc directory)","text":"<p>Nomad has issues following symlinks in the data_dir, you can solve it by replacing it for the real path. </p> <p>e.g in <code>nomad.hcl</code>:</p> <pre><code>- data_dir = \"/opt/build/nomad\"\n+ data_dir = \"/Volumes/build/nomad\"\n</code></pre>"},{"location":"infrastructure-new-architectures/","title":"New architectures","text":""},{"location":"infrastructure-new-architectures/#adding-new-architectures-to-cvmfs","title":"Adding new Architectures to CVMFS","text":""},{"location":"infrastructure-new-architectures/#adding-new-compilers-to-cvmfs","title":"Adding new compilers to CVMFS","text":"<p>In order to add a new compiler in CVMFS, one needs to first fix the GCC-Toolchain recipe. In particular <code>$ModulesCurrentModulefile</code> should change to <code>\\$ModulesCurrentModulefile</code> (FIXME for next time).</p> <p>Finally, one needs to create a symlink in <code>/cvmfs/alice.cern.ch/etc/toolchain/modulefiles/&lt;architecture&gt;/GCC-&lt;version&gt;</code>  which points to <code>../../../../../el7-x86_64/Modules/modulefiles/GCC-Toolchain/&lt;version&gt;-&lt;revision&gt;</code>.</p>"},{"location":"infrastructure-new-architectures/#enabling-a-new-compiler-on-hyperloop","title":"Enabling a new compiler on Hyperloop","text":"<p>Besides adding the compiler to CVMFS as specified above, one needs to release again jq using the new compiler.</p>"},{"location":"infrastructure-nightly/","title":"Nightly builds","text":""},{"location":"infrastructure-nightly/#integration-builds","title":"Integration builds","text":"<p>So called integration (or nightly) builds are the pivotal part of a continuous integration system. They get triggered as often as possible using the tip of the branch of a repository and they usually include as many tests as possible which can help making sure that the branch is in the best possible state.</p> <p>In order to drive ALICE builds we use Jenkins while results of the builds are shown in https://alijenkins.cern.ch/job/DailyBuilds/.</p>"},{"location":"infrastructure-nightly/#troubleshooting","title":"Troubleshooting","text":""},{"location":"infrastructure-nightly/#alibuild-errors-out-with-a-conflict-on-s3","title":"<code>aliBuild</code> errors out with a conflict on S3","text":"<p><code>aliBuild</code> uploads tarballs to its remote store. However, it cannot just upload one file -- it needs to upload the tarball itself under <code>TARS/&lt;arch&gt;/store/</code>, a \"symlink\" to it under <code>TARS/&lt;arch&gt;/&lt;package&gt;/</code> and various \"symlinks\" specifying the new tarball's dependencies under <code>TARS/&lt;arch&gt;/dist{,-direct,-runtime}/&lt;package&gt;/&lt;package&gt;-&lt;version&gt;-&lt;revision&gt;/</code>.</p> <p>When aliBuild is killed while uploading tarballs, it can leave the repository in a partial state.</p> <p>If this happens, you need to manually delete the partial symlinks:</p> <pre><code>arch=slc9_x86-64 package=O2 version=daily-20240313-0100 revision=1\ns3cmd rm \"s3://alibuild-repo/TARS/$arch/$package/$package-$version-$revision.$arch.tar.gz\"\ns3cmd rm -r \"s3://alibuild-repo/TARS/$arch/dist/$package/$package-$version-$revision/\"\ns3cmd rm -r \"s3://alibuild-repo/TARS/$arch/dist-runtime/$package/$package-$version-$revision/\"\ns3cmd rm -r \"s3://alibuild-repo/TARS/$arch/dist-direct/$package/$package-$version-$revision/\"\n</code></pre> <p>Since the main tarball in <code>TARS/&lt;arch&gt;/store/</code> is uploaded last, it likely does not exist in this case, but if it does, find its name using:</p> <pre><code>s3cmd ls -r \"s3://alibuild-repo/TARS/$arch/store/\" | grep -F \"/$package-$version-$revision.$arch.tar.gz\"\n2024-03-13 00:28   1682231289  s3://alibuild-repo/TARS/slc9_x86-64/store/f2/f242f6e4ef58e8f15f3b410729bee6fdb562d790/O2-daily-20240313-0100-1.slc9_x86-64.tar.gz\n</code></pre> <p>The file name to delete is shown in the output above:</p> <pre><code>s3cmd rm 's3://alibuild-repo/TARS/slc9_x86-64/store/f2/f242f6e4ef58e8f15f3b410729bee6fdb562d790/O2-daily-20240313-0100-1.slc9_x86-64.tar.gz'\n</code></pre>"},{"location":"infrastructure-nightly/#daily-build-issues","title":"Daily build issues","text":"<p>Some techniques on how to debug issues with the daily builds</p>"},{"location":"infrastructure-nightly/#jenkins-build","title":"Jenkins build","text":"<p>Didn't succeed / red status</p> <p>Probably a problematic PR was merged to either alidist or some of the source repos. Logs available here https://alijenkins.cern.ch/job/DailyBuilds/job/DailyO2Physics-slc9/</p> <p>Not all builds are fully deterministic, so sometimes a retry is enough to fix the issue.</p> <p>Didn't trigger</p> <p>Was Jenkins down at the time? The build is triggered automatically by a cron-like counter in the Jenkins job config</p> <p>If retrying the build, make sure the new tag name is the right one (ending in 0000, has the right date, etc), otherwise the following jobs will fail</p>"},{"location":"infrastructure-nightly/#no-build-system-email-was-sent","title":"No build system email was sent","text":"<p>The publishing cronjob in cvmfs-alice.cern.ch probably failed/didn't run. There's some info available on how it works in the machine MOTD, and on the user cvalice's crontab</p>"},{"location":"infrastructure-nightly/#the-tag-is-not-present-on-alien","title":"The tag is not present on AliEn","text":"<p>Did the publish-alien nomad job fail? It might also not be able to find a free machine to land on, if the cluster is too busy</p>"},{"location":"infrastructure-nightly/#the-tag-was-built-correctly-but-it-fails-during-runtime","title":"The tag was built correctly, but it fails during runtime","text":"<p>You can spin up a container with the same environment as the grid using the following command:</p> <pre><code>/cvmfs/alice.cern.ch/containers/bin/apptainer/x86_64/current/bin/apptainer exec -B /cvmfs:/cvmfs -C /cvmfs/alice.cern.ch/containers/fs/apptainer/compat_el7-x86_64/ /bin/bash\n</code></pre> <p>This will give you a shell to try and reproduce the issue there. For example, testing a broken modulefile:</p> <pre><code>/cvmfs/alice.cern.ch/bin/alienv printenv VO_ALICE@AliPhysics::vAN-20241003_O2-1 VO_ALICE@APISCONFIG::V1.1x\n</code></pre>"},{"location":"infrastructure-nightly/#nightly-repository","title":"Nightly repository","text":"<p>In order to speed up builds we maintain a nightly repository which caches packages which were already built previously. This consist of a CERN S3 bucket, <code>s3://alibuild-repo/</code>, which is also accessible over HTTP at https://s3.cern.ch/swift/v1/alibuild-repo/. You can browse it in CERN OpenStack, when switched to the \"ALICE Release Testing\" project.</p> <p>In order to upload tarballs to the repository, use <code>--remote-store b3://alibuild-repo::rw</code> with <code>aliBuild</code>, while having the <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> environment variables set.</p>"},{"location":"infrastructure-nomad-host/","title":"Nomad cluster setup","text":""},{"location":"infrastructure-nomad-host/#cluster-architecture","title":"Cluster architecture","text":"<p>See here for an explanation of the underlying infrastructure.</p>"},{"location":"infrastructure-nomad-host/#nomad-consul-and-vault-setup-notes","title":"Nomad, Consul and Vault setup notes","text":""},{"location":"infrastructure-nomad-host/#nomad-and-consul-setup-on-non-openstack-machines","title":"Nomad and Consul setup on non-Openstack machines","text":"<ol> <li>Add Hashicorp apt repo to get modern consul/nomad packages (the Ubuntu-packaged ones are too old to work with our config):    <pre><code>curl -fsSL https://apt.releases.hashicorp.com/gpg | apt-key add -\ncat &lt;&lt; EOF &gt; /etc/apt/sources.list.d/hashicorp.list\n# Added &lt;date&gt; by &lt;you&gt;.\n# Required for newer versions of nomad and consul -- Ubuntu repo versions are too old.\ndeb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\nEOF\napt update\napt install nomad consul\nsystemctl stop nomad consul   # for now\nmkdir /build/consul /build/nomad\nchown consul:consul /build/consul\n</code></pre></li> </ol> <p>Ignore any errors about packages not being able to create directories in <code>/opt</code>. Jalien stuff is mounted there, and consul/nomad would only create their default data directory there (which we don't use). 2. Use <code>consul.hcl</code> and <code>nomad.hcl</code> from Puppet (use the links or get them from <code>/etc/nomad.d</code> / <code>/etc/consul.d</code> on a Puppet-managed host), but adapt by setting the correct IP address for <code>advertise_addr</code> and/or <code>bind_addr</code>, and substituting Teigi secrets manually.</p> <p>Also, change the location of Grid certificates if necessary, both for nomad's multiple <code>tls</code> settings and for nomad's <code>host_volumes</code>. Nomad itself runs as root, so no filesystem ACL adjustments should be necessary (but as before, the CI should be allowed access to them via the <code>mesos{ci,daq}</code> users).</p> <p>For <code>alissandra</code> machines, reserve half the resources so the CI system doesn't take up too much of the host. 3. Add a <code>server=/consul/137.138.62.94</code> line to <code>/etc/dnsmasq.conf</code> and restart <code>dnsmasq.service</code>. This is required for Nomad to look up Vault hosts at <code>vault.service.consul</code>. 4. Start the daemons:    <pre><code>systemctl enable --now nomad consul\njournalctl -fu nomad   # to watch logs\n</code></pre></p> <p>An autogenerated nomad-client entry for the host should now appear in consul, and the new nomad client should appear in the nomad web UI.</p>"},{"location":"infrastructure-nomad-host/#vault-settings-applied-to-our-cluster","title":"Vault settings applied to our cluster","text":""},{"location":"infrastructure-nomad-host/#allow-nomad-clients-access-to-secrets","title":"Allow Nomad clients access to secrets","text":"<p>Secret substitution happens on the nomad client that receives a job. It has a <code>nomad-server</code> token, with which it has to get a temporary <code>nomad</code> token (which it in turn uses to fetch secrets).</p> <pre><code>vault write auth/token/roles/nomad-server allowed_policies='default, nomad, nomad-server' orphan=true\nvault write auth/token/roles/nomad allowed_policies='default, nomad' orphan=true token_period=1d\n</code></pre>"},{"location":"infrastructure-nomad-host/#allow-issuing-essentially-non-expiring-tokens","title":"Allow issuing essentially non-expiring tokens","text":"<p>By default, tokens expire after a month, which means the nomad cluster breaks and tokens have to be manually updated.</p> <p>Change the default max expiry time to 100 years instead.</p> <pre><code>vault write sys/auth/token/tune default_lease_ttl=3155760000s max_lease_ttl=3155760000s\n</code></pre> <p>Tokens can still be revoked manually using any one of the following commands:</p> <pre><code>vault token revoke '&lt;secret token here&gt;'\n# Or alternatively:\nvault token revoke -accessor '&lt;token accessor here&gt;'\n</code></pre> <p>This will revoke any child tokens of the given token as well, unless the <code>-mode=orphan</code> option is given.</p>"},{"location":"infrastructure-nomad-host/#troubleshooting","title":"Troubleshooting","text":""},{"location":"infrastructure-nomad-host/#leftover-consul-services-arent-deregistered","title":"Leftover Consul services aren't deregistered","text":"<p>Sometimes, Consul can get into a state where services were registered but never deregistered. In particular, this happens when a host changes its public IP address -- in that case, the old service remains registered because a Consul agent with the same host name is still available, even though the service's public IP address is wrong.</p> <p>If this happens, deregister the service with the wrong IP manually by running the following: <pre><code>ssh host-with-changed-ip.cern.ch \"CONSUL_HTTP_TOKEN=$(pass .../consul-token)\" consul services deregister -id offending-service-id\n</code></pre> ...where the <code>pass</code> command prints out your Consul token, <code>host-with-changed-ip</code> is the affected hostname, and <code>offending-service-id</code> is the ID of the old service with the wrong IP, e.g. <code>_nomad-client-xd2yun6h34z5nni56pdncbqb6b3mjfcf</code>.</p> <p>It is critical that the <code>consul services deregister</code> command runs on the host that originally registered the service. If you run the plain <code>consul</code> command locally, e.g. against one of the Consul master nodes, it will fail with a \"service not found\" error, even if the ID is correct.</p>"},{"location":"infrastructure-nomad/","title":"Build infrastructure on Nomad","text":"<p>The CI system uses Nomad for job scheduling, plus Consul for job discovery and DNS, and Vault to store secrets.</p> <p>These all have web interfaces. If you have access, you can log in at https://alinomad.cern.ch, https://aliconsul.cern.ch and https://alivault.cern.ch if on the CERN network.</p> <p>Jobs are defined in a dedicated git repository.</p>"},{"location":"infrastructure-nomad/#essential-ci-operations-guide","title":"Essential CI operations guide","text":"<p>For hints on how to adapt the instructions in this section to jobs other than the CI job, see the following sections.</p>"},{"location":"infrastructure-nomad/#where-to-find-logs","title":"Where to find logs","text":"<p>Logs are written out to disk by the Nomad agent under an allocation's <code>alloc/logs/</code> directory. They can also be fetched or streamed using the Nomad command-line client:</p> <pre><code># Stream logs live, as they are written:\nnomad alloc logs -stderr -tail -f '&lt;alloc-uuid&gt;'\n# Fetch and print all stored logs for this allocation (warning: lots of text!):\nnomad alloc logs -stderr '&lt;alloc-uuid&gt;'\n# If a job only has one allocation, you can directly use `-job`:\nnomad alloc logs -stderr -tail -f -job repo\n</code></pre> <p>If you use the last command (the one with <code>-job</code>) on a job that has multiple allocations (such as most CI jobs), Nomad will pick a random allocation within the job and give you its logs.</p> <p>Run <code>nomad alloc logs -help</code> for more information on the command and its options.</p>"},{"location":"infrastructure-nomad/#stopping-and-restarting-ci-jobs","title":"Stopping and restarting CI jobs","text":"<p>If you want to fully bring down and redeploy a CI job, you must do this manually by stopping and rescheduling it.</p> <p>Nomad has a \"restart\" facility for individual allocations, which may suffice, but this only reschedules individual allocs, and not necessarily for long enough for e.g. resource redistribution to happen properly. For instance, if you have one alloc waiting for a spot on a high-memory machine, and something else that doesn't need a lot of memory is taking that spot, then you may have to fully stop the latter alloc's job for the former to be properly scheduled, and afterwards, redeploy the stopped job.</p> <p>In order to fully stop and redeploy a job, run the following commands (<code>ci-mesosci-cs8</code> chosen as an example):</p> <pre><code>cd ci-jobs/ci\n# First, make sure the running job is identical to the local declaration:\nlevant render -var-file mesosci-cs8.yaml | nomad job plan -  # no changes should be shown\n# Stop all allocations of the running job:\nnomad job stop ci-mesosci-cs8\n# Now redeploy the job from the current definitions:\nlevant render -var-file mesosci-cs8.yaml | nomad job plan -  # make sure scheduling is fine\nlevant render -var-file mesosci-cs8.yaml | nomad job run -   # actually redeploy the job\n</code></pre> <p>Build areas are preserved across allocation restarts, but only if the replacement alloc runs on the same host as its predecessor. If this is not the case, it's not worth transferring the entire build directory over the network, so we just start from scratch instead. This is implemented using the following settings in the CI job definition:</p> <pre><code>group \"ci\" {\n  ephemeral_disk {\n    sticky = true\n    migrate = false\n  }\n}\n</code></pre>"},{"location":"infrastructure-nomad/#scaling-a-ci-job","title":"Scaling a CI job","text":"<p>If you want to permanently change the number of running CI jobs for a specific type of builder (e.g. the <code>mesosci-cs8</code> one), change the desired number of builders by setting the value of <code>num_builders</code> in <code>mesosci-cs8.yaml</code>.</p> <p>Deploy your scaling update to the cluster by running the usual commands:</p> <pre><code>cd ci\n$EDITOR mesosci-cs8.yaml                                         # change num_builders value\nlevant render -var-file mesosci-cs8.yaml | nomad job validate -  # check syntax\nlevant render -var-file mesosci-cs8.yaml | nomad job plan -      # make sure only your desired changes will be applied\nlevant render -var-file mesosci-cs8.yaml | nomad job run -       # actually deploy your changes\ngit add mesosci-cs8.yaml &amp;&amp; git commit                           # track your changes\n</code></pre> <p>If you want to scale a job without committing this change to the Git repository, this can be done like so:</p> <pre><code>nomad job scale ci-mesosci-cs8 N    # N is the desired number of builders for this job\n</code></pre> <p>The above command will automatically install a new <code>config/workers-pool-size</code> file into the working area of the running builders without restarting them.</p>"},{"location":"infrastructure-nomad/#deploying-changes-to-the-ci-job-template","title":"Deploying changes to the CI job template","text":"<p>When changing the template itself (i.e. the <code>ci.nomad</code> file), the changes must be deployed for each YAML file, as each declares a separate instance of the templated job.</p> <pre><code>cd ci\n$EDITOR ci.nomad\nfor f in *.yaml; do levant render -var-file \"$f.yaml\" | nomad job validate -; done\n# Now, for each .yaml file in the directory:\nlevant render -var-file vars.yaml | nomad job plan -      # make sure your desired changes will be applied\nlevant render -var-file vars.yaml | nomad job run -       # actually deploy your changes\ngit add ci.nomad &amp;&amp; git commit                            # track your changes\n</code></pre> <p>While there's no harm in running the syntax validation step in a loop, it's probably better to do the actual deployment (i.e. <code>nomad job run</code>) manually for each YAML file, so that issues with the deployment can be caught early.</p>"},{"location":"infrastructure-nomad/#troubleshooting-placement-failures","title":"Troubleshooting placement failures","text":"<p>If the Nomad scheduler fails to place your job, you will see a message like this when you run <code>nomad job plan</code>:</p> <pre><code>Scheduler dry-run:\n- WARNING: Failed to place all allocations.\n  Task Group \"ci\" (failed to place 10 allocations):\n    * Constraint \"${attr.kernel.name} = linux\": 3 nodes excluded by filter\n    * Constraint \"${meta.allow_compilation} = true\": 3 nodes excluded by filter\n    * Resources exhausted on 39 nodes\n    * Dimension \"cores\" exhausted on 24 nodes\n    * Dimension \"disk\" exhausted on 9 nodes\n    * Dimension \"cpu\" exhausted on 6 nodes\n</code></pre> <p>In this case, check the following:</p> <ol> <li>Check that the cluster actually has space for your job, and that your job declares the correct resource requirements.</li> </ol> <p>For example, not all Openstack machines have a separate build disk of 500 GiB, so a CI job legitimately cannot be scheduled on these.</p> <ol> <li> <p>If your job requires, for instance, lots of memory, but all the high-memory machines are taken by other jobs, you may have to stop and reschedule those other jobs while deploying yours. Assuming that the other jobs don't need a lot of memory, they should be scheduled on other free machines when you restart them after deploying your job.</p> </li> <li> <p>If your job requires a lot of disk space, make sure that Nomad's internal tracking of available disk space is correct. You can do this using the <code>nomad-diskfree</code> script and looking for any warnings on hosts that don't have any allocations running.</p> </li> </ol> <p>If you see warnings from <code>nomad-diskfree</code>, <code>ssh</code> into the affected machine, manually clean up under <code>/build/nomad/alloc</code> if necessary, and run <code>systemctl restart nomad</code> to reset Nomad's idea of available disk space. If you then run <code>nomad job plan</code> again, you should see fewer unplaced allocations.</p>"},{"location":"infrastructure-nomad/#developing-locally","title":"Developing locally","text":""},{"location":"infrastructure-nomad/#setting-up-your-local-environment","title":"Setting up your local environment","text":"<p>You will need to install a reasonably recent versions of Nomad to parse existing job declarations. Additionally, you should install the latest version of Levant; ideally version 0.3.1 or later.</p> <p>Set the following environment values to connect to ALICE's scheduling cluster:</p> <p>More info on how to get the certificates here</p> <pre><code>export NOMAD_ADDR='https://alinomad.cern.ch:443'\nexport CONSUL_HTTP_ADDR='https://aliconsul.cern.ch:443'\nexport VAULT_ADDR='https://alivault.cern.ch:443'\n# These .pem files must not be password-protected.\n# For extra security, make sure they are mode 0600 (owner read-write only).\nexport {NOMAD,CONSUL,VAULT}_CACERT='&lt;path/to/cern-ca-bundle.crt&gt;'\nexport {NOMAD,CONSUL,VAULT}_CLIENT_KEY='&lt;path/to/grid-personal-key.pem&gt;'\nexport {NOMAD,CONSUL,VAULT}_CLIENT_CERT='&lt;path/to/grid-personal-cert.pem&gt;'\n# Export your access tokens to the cluster, so that the command-line nomad,\n# consul and vault clients can use them:\nexport NOMAD_TOKEN='&lt;nomad access token UUID&gt;'\nexport CONSUL_HTTP_TOKEN='&lt;consul access token UUID&gt;'\nexport VAULT_TOKEN='&lt;vault access token UUID&gt;'\n# Alternatively, set these tokens only for commands that need them, e.g.\n# by using aliases to retrieve the secrets and invoke the respective command:\nalias nomad='NOMAD_TOKEN=$(pass cern/ci/nomad-token | head -1) \\nomad'\nalias levant='NOMAD_TOKEN=$(pass cern/ci/nomad-token | head -1) \\levant'\nalias consul='CONSUL_HTTP_TOKEN=$(pass cern/ci/consul-token | head -1) \\consul'\nalias vault='VAULT_TOKEN=$(pass cern/ci/vault-token | head -1) \\vault'\n</code></pre> <p>However, this only works for machines on the CERN network. If dialling in from outside, you'll have to set up a proxy (e.g. using SSH forwarding) like so, in addition to setting the <code>*_TOKEN</code> and certificate-related environment variables as above:</p> <pre><code>ssh -L localhost:4646:alimesos01.cern.ch:4646 \\\n    -L localhost:8500:alimesos01.cern.ch:8500 \\\n    -L localhost:8200:alimesos01.cern.ch:8200 \\\n    -N alimesos01.cern.ch &amp;\nexport NOMAD_ADDR='https://localhost:4646'\nexport CONSUL_HTTP_ADDR='https://localhost:8500'\nexport VAULT_ADDR='https://localhost:8200'\nexport {NOMAD,CONSUL,VAULT}_TLS_SERVER_NAME=alimesos01.cern.ch\n</code></pre>"},{"location":"infrastructure-nomad/#writing-job-declarations","title":"Writing job declarations","text":"<p>Jobs are defined using Levant templates. While plain nomad templating is powerful, it does not allow variable job identifiers (which are crucial for declaring e.g. multiple similar Jenkins builders or CI workers). Levant allows templating on top of the HCL job specification read by nomad.</p> <p>As Levant bundles a version of the Nomad client, Levant <code>0.3.1</code> or later is required in order to parse the HCL job declarations we use.</p>"},{"location":"infrastructure-nomad/#simple-job-declarations-eg-rsync-server","title":"Simple job declarations (e.g. <code>rsync</code> server)","text":"<p>Simple job declarations, i.e. those that declare only a single job, don't use Levant for templating at all. They are simple HCL files stored in the root directory of the [ci-jobs repository][jobs-decls-repo], named <code>&lt;job-name&gt;.nomad</code>.</p> <p>An example of this is the declaration for the <code>rsync</code> server that serves tarballs for <code>aliBuild</code>.</p> <p>In order to deploy this job, simply run the following commands, checking the output of each:</p> <pre><code>nomad job validate repo.nomad   # check syntax\nnomad job plan repo.nomad       # check if the job can be scheduled\nnomad job run repo.nomad        # actually run the job\n</code></pre>"},{"location":"infrastructure-nomad/#complex-templated-job-declarations-eg-ci","title":"Complex, templated job declarations (e.g. CI)","text":"<p>Complicated job declarations are broken up into a common, templated declaration, and multiple YAML \"variable files\" to declare the variations of the base job to be deployed. These should be collected into a single directory, with multiple <code>.yaml</code> files, but only one <code>.nomad</code> file per directory.</p> <p>An example of this is the CI job. It contains a <code>ci.nomad</code> file, which is the general job declaration. This file is processed first by Levant (in the <code>levant render</code> step above). Levant only processes directives surrounded by double square brackets (<code>[[ ... ]]</code>). The result of this first processing step is a Nomad job declaration in HCL syntax, which can be passed directly to Nomad.</p> <p>What values Levant inserts into the file is determined by the YAML file it is given. The structure of these files depends entirely on what values the template expects, but for CI jobs, an example is the <code>mesosci-slc7-o2physics.yaml</code> variable file.</p> <p>In order to run or update this job, run the following commands, replacing <code>vars.yaml</code> with the variable file for the instance you want to deploy, and checking the output of each command before running the next one:</p> <pre><code>cd ci    # so that levant picks up the correct .nomad file\nlevant render -var-file vars.yaml | nomad job validate -  # check syntax\nlevant render -var-file vars.yaml | nomad job plan -      # make sure job can be scheduled\nlevant render -var-file vars.yaml | nomad job run -       # actually run job\n</code></pre>"},{"location":"infrastructure-nomad/#tips-and-tricks-for-writing-nomad-job-declarations","title":"Tips and tricks for writing Nomad job declarations","text":""},{"location":"infrastructure-nomad/#using-vault-secrets","title":"Using Vault secrets","text":"<p>If you want to use Vault secrets in your job declaration, you can substitute them inside of templates.</p> <p>For instance, to assign secrets to environment variables that will be set when the job runs, use a block like the following inside your <code>task</code> block:</p> <pre><code>template {\n  data = &lt;&lt;-EOD\n    {{ \"{{\" }} with secret \"kv/data/my-secret-name\" }}\n    MY_SECRET={{ \"{{\" }} .Data.data.my_secret | toJSON }}\n    MY_OTHER_SECRET={{ \"{{\" }} .Data.data.my_other_secret | toJSON }}\n    {{ \"{{\" }} end }}\n    EOD\n  env = true\n  destination = \"${NOMAD_SECRETS_DIR}/secrets.env\"\n  perms = \"400\"\n  change_mode = \"restart\"\n}\n\n# Required in order to read vault secrets.\nvault {\n  policies = [\"nomad\"]\n}\n</code></pre> <p>This example assumes that you have a secret called <code>my-secret-name</code> stored in Vault, whose contents are a JSON object of the form:</p> <pre><code>{\n  \"my_secret\": \"my sup3r s3cr3t\",\n  \"my_other_secret\": \"my 0th3r s3cr3t\"\n}\n</code></pre>"},{"location":"infrastructure-nomad/#troubleshooting","title":"Troubleshooting","text":""},{"location":"infrastructure-nomad/#stuck-allocationsjobs","title":"Stuck allocations/jobs","text":"<p>When a job is not able to be deleted and recreated, you can force the deletion using the following commands (requires nomad management token):</p> <pre><code>nomad job stop -purge &lt;job-name&gt;\nnomad system gc\n</code></pre>"},{"location":"infrastructure-nomad/#nomad-error-initializing-client-tls-failed-to-parse-private-key","title":"Nomad error initializing client: tls: failed to parse private key","text":"<p>If you are on macOS you'll need an unencrypted key, you can export it from your certificate with a command like this (note the <code>-nodes</code> flag)</p> <pre><code>openssl pkcs12 -nocerts -in ~/Downloads/myCertificate.p12 -out ~/.globus/userkey.pem -nodes\n</code></pre> <p>Otherwise you'll probably get the following error:</p> <pre><code>Error initializing client: tls: failed to parse private key\n</code></pre>"},{"location":"infrastructure-o2-branches/","title":"O2 Git Branches","text":""},{"location":"infrastructure-o2-branches/#stable-branches-for-o2","title":"Stable branches for O2","text":"<p>The O2 software is developed continuously in the <code>dev</code> branch. Both the synchronous and the asynchronous processing have their own stable branches, <code>stable-sync</code> and <code>stable-async</code>, which follow the <code>dev</code> branch closely. The following procedure has been agreed upon for managing the two stable branches:</p> <ol> <li>Both synchronous processing at P2 and the asynchronous processing on the grid might require quick fixes which should not rely on coordination between the two. For that reason there are two stable branches <code>stable-sync</code> and <code>stable-async</code>.</li> <li>No development shall go into these branches. All developments must go into <code>dev</code>. They will not be used to port fixes by user requests.</li> <li>When requested by RC or by experts for sync / async reconstruction, we can cherry-pick fixes / features from <code>dev</code> in one of the stable branches. We will not do extensive back-porting. If the patches do not apply cleanly or with only trivial merge conflicts, we do not cherry-pick but we will merge the full <code>dev</code> branch into the stable branch.</li> <li>We will regularly merge the full <code>dev</code> branch into the stable branches. For synchronous reconstruction usually synchronized with the large software updates. After merging, <code>stable-*</code> will be hard reset to the state of <code>dev</code>.</li> <li>The stable branches shall not split up further, i.e. we only either cherry-pick individual commits on top, or we merge the full <code>dev</code>.</li> <li>Nightly builds for <code>dev</code> are unaffected, we do not do nightly builds for the stable branch. Instead, tags of the stable branch are only built manually via jenkins when needed.</li> <li>We use the same validation mechanism for tags of the stable branch as for the <code>dev</code> branch, i.e. the FST for <code>stable-sync</code>, and the release validation for <code>stable-async</code>.</li> <li>The naming scheme for tags of the stable branch is [last tag in dev branch] + \".\" + [incrementing number].    If changes to an existing tag are carried out, you can instead add an incrementing letter, for example, <code>async-20231102.3</code> -&gt; <code>async-20231102.3a</code> -&gt; <code>async-20231102.3b</code>.</li> </ol> <p>The procedure for cherry-picking and for merging is described below. The following branching scheme should give an overview: </p>"},{"location":"infrastructure-o2-branches/#cherry-picking-specific-commits-from-dev-into-stable-","title":"Cherry-picking specific commits from <code>dev</code> into <code>stable-*</code>","text":"<ul> <li>We start with the branch <code>stable-sync</code> at commit <code>6d54961f81f6c129a28b655baa4101b0ecd41535</code>, tag <code>epn-20220812</code>.</li> </ul> <ul> <li>The remote repository is set up with write access under a special name \"upstream-write\", to make sure that no accidental push to \"upstream\" is tried (upstream is configured as read-only via http).</li> <li>First, rebase to make sure you are on the latest state of the upstream branch.</li> <li>Cherry-picking the 2 commits <code>0c3c41a93e2e2bbd1ce650e852128b66d38c907a</code> and <code>04f7383a49287af12c37c5bb88cb36f7fcc8bc22</code>.</li> <li>Please make sure to cherry-pick them in the order they are applied in the <code>dev</code> branch.</li> <li>Only accept cherry-picks that apply cleanly, or if the merge conflicts are trivial!</li> <li>When you want to build that version, tag it using the naming scheme mentioned above. In this case as <code>epn-20220812.1</code>.</li> <li>Push the branch and the tag</li> </ul> <p>The console output looks as follows:</p> <pre><code>qon@qon ~/alice/O2 $ git checkout stable-sync\nAlready on 'stable-sync'\nqon@qon ~/alice/O2 $ git fetch upstream\nqon@qon ~/alice/O2 $ git rebase upstream/stable-sync\nCurrent branch stable-sync is up to date.\nqon@qon ~/alice/O2 $ git cherry-pick 0c3c41a93e2e2bbd1ce650e852128b66d38c907a\n[stable-sync 77305662736] [EMCAL-566] print detailed message if gaus fit fails\nAuthor: Joshua Koenig &lt;joshua.konig@cern.ch&gt;\nDate: Wed Aug 10 10:51:08 2022 +0200\n3 files changed, 77 insertions(+), 67 deletions(-)\nqon@qon ~/alice/O2 $ git cherry-pick 04f7383a49287af12c37c5bb88cb36f7fcc8bc22\n[stable-sync b2175be0ffc] MeanVertex X and Y coordinate depend on Z (#9315)\nAuthor: Chiara Zampolli &lt;chiara.zampolli@cern.ch&gt;\nDate: Mon Aug 15 17:44:26 2022 +0200\n9 files changed, 434 insertions(+), 266 deletions(-)\nqon@qon ~/alice/O2 $ git tag -a epn-20220812.1\nhint: Waiting for your editor to close the file...\nqon@qon ~/alice/O2 $ git push upstreamwrite stable-sync\nEnumerating objects: 53, done.\nCounting objects: 100% (53/53), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (22/22), done.\nWriting objects: 100% (28/28), 7.45 KiB | 7.45 MiB/s, done.\nTotal 28 (delta 22), reused 9 (delta 4), pack-reused 0\nremote: Resolving deltas: 100% (22/22), completed with 20 local objects.\nTo github.com:AliceO2Group/AliceO2.git\n  b2175be0ffc..b3dd9e5135c  stable-sync -&gt; stable-sync\nqon@qon ~/alice/O2 $ git push upstreamwrite epn-20220812.1\n[...]\n</code></pre> <ul> <li>See below the state of the current branch. We are at the previous state (<code>epn-20220812</code>) with the two cherry-picked commits on top. And this state is tagged as <code>epn-20220812.1</code>.</li> </ul> <p></p>"},{"location":"infrastructure-o2-branches/#merging-the-changes-from-dev-into-stable-","title":"Merging the changes from <code>dev</code> into <code>stable-*</code>","text":"<p>Next we want to bring <code>stable-sync</code> to the state of the current <code>dev</code>. For this we merge <code>upstream/dev</code> into the current branch <code>stable-sync</code>. (We could also merge the latest nightly-tag, if that nightly tag is what is running on the EPNs.) - We merge with the option <code>-X theirs</code> to make sure that in case of a conflict, we use the <code>dev</code> branch. - Afterwards, in case the merge did not yield the exact state of <code>upstream/dev</code>, we run a <code>git diff</code> to <code>upstream/dev</code>, apply possible changes to the working tree, and amend the merge commit by it. The exact commands for this are:</p> <pre><code>git diff upstream/dev | git apply --allow-empty -R --index; git commit --amend --no-edit\n</code></pre> <ul> <li>Here again the possible console output:</li> </ul> <pre><code>qon@qon ~/alice/O2 $ git fetch upstream\nqon@qon ~/alice/O2 $ git merge -X theirs upstream/dev\nAuto-merging Common/SimConfig/include/SimConfig/SimConfig.h\nAuto-merging Common/Utils/include/CommonUtils/BoostHistogramUtils.h\nAuto-merging Detectors/EMCAL/calibration/include/EMCALCalibration/EMCALCalibExtractor.h\nhint: Waiting for your editor to close the file...\nMerge made by the 'ort' strategy.\nCODEOWNERS                                                                     |    4 +-\nCommon/SimConfig/include/SimConfig/SimConfig.h                                 |    6 +-\nCommon/SimConfig/src/SimConfig.cxx                                             |    6 +-\nCommon/Utils/CMakeLists.txt                                                    |    2 +-\nCommon/Utils/include/CommonUtils/BoostHistogramUtils.h                         |  142 +++++++++++++++++++++++++++++++-\nCommon/Utils/include/CommonUtils/RngHelper.h                                   |    6 +-\n[...]\n78 files changed, 2518 insertions(+), 1572 deletions(-)\nqon@qon ~/alice/O2 $ git diff upstream/dev | git apply --allow-empty -R --index\nqon@qon ~/alice/O2 $ git commit --amend --no-edit\n[stable-sync 005d1dd4aff] Merge remote-tracking branch 'upstream/dev' into stable-sync\nDate: Wed Aug 17 14:15:22 2022 +0200\n</code></pre> <ul> <li>Finally, make sure we are exactly at <code>upstream/dev</code>. The following diff must not show any difference.</li> </ul> <pre><code>qon@qon ~/alice/O2 $ git diff upstream/dev | cat\nqon@qon ~/alice/O2 $\n</code></pre> <ul> <li> <p>Now the <code>stable-sync</code> branch is exactly at the state of <code>upstream/dev</code>, and from here on we can cherry-pick further commits from <code>upstream/dev</code> that were committed after the merge.</p> </li> <li> <p>Please see the final state in the figure below. From the point we started branching of (<code>epn-20220812</code>) the <code>stable-sync</code> branch had 2 commits cherry-picked, and then it is merged with <code>upstream/dev</code>.</p> </li> </ul> <p></p>"},{"location":"infrastructure-pr-testing/","title":"Pull Request Builders","text":"<p>The ALICE Github PR builder is implemented as a set of independent agents which looks at a portion of the phase space of the PRs available for testing. This means that if there are 4 builders deployed each one of them will build on average 1/4th of the PRs. This avoids the need for a centralised scheduling service. Moreover, since the process of checking a PR is not done once a given PR is built, but only when it's merged, builders keep retrying to build even PR which were previously successfully built. This is because the boundary condition of the PR checking could be different (e.g. merge conflict might happen a previously unresponsive service is back to production) and therefore the test of a given PR is considered complete only when the PR is merged.</p> <p>By default the builders will behave in the following manner:</p> <ul> <li>Wait for a configurable number of seconds</li> <li>Check if there is one or more untested PR. If yes, start building them   and then go back to the starting point.</li> <li>Check if there are pull requests which were previously checked and had   a failure. If yes, test one of them and then go back to the starting point.</li> <li>Check if there are pull requests which were previously checked and had did   not have a failure. If yes, test one of them and then go back to the starting   point.</li> </ul> <p>We use Nomad to deploy the builders on Linux and MacOS.</p>"},{"location":"infrastructure-pr-testing/#essential-operations-guide","title":"Essential operations guide","text":"<p>See also: the essential CI operations guide for the ALICE Nomad deployment.</p> <ul> <li>Adding a package to be tested</li> <li>Setup your environment</li> <li>Listing active PR checker</li> <li>Scaling the number of checkers</li> <li>Creating a new checker</li> <li>Updating the PR checker</li> <li>Restarting a checker</li> <li>Inspecting the checkers</li> <li>Monitoring the checkers</li> </ul>"},{"location":"infrastructure-pr-testing/#adding-a-package-to-be-tested","title":"Adding a package to be tested","text":"<p>Each checker deployed on Nomad can test multiple packages. These are declared as <code>*.env</code> files in a subdirectory of ali-bot, following the pattern:</p> <pre><code>ali-bot/ci/repo-config/&lt;mesos role&gt;/&lt;container&gt;/&lt;short name&gt;.env\n</code></pre> <p>The <code>DEFAULTS.env</code> files in the directory tree are special -- they are sourced before the applicable <code>*.env</code> file, and can provide default values for various variables.</p> <p>The most relevant variables you can set through the <code>*.env</code> file are:</p> <ul> <li><code>ALIBUILD_DEFAULTS</code>: what to pass to alibuild using its <code>--defaults</code> flag</li> <li><code>ALIBUILD_O2_TESTS</code>, <code>ALIBUILD_O2PHYSICS_TESTS</code>, <code>ALIBUILD_XJALIENFS_TESTS</code>: set these if O2, O2Physics and/or xjalienfs unit tests should be run as part of the check</li> <li><code>CHECK_NAME</code>: the display name for this check, shown on GitHub</li> <li><code>CI_NAME</code>: an internal name for this check</li> <li><code>DEVEL_PKGS</code>: a newline-separated list of repositories to install as \"development packages\" for the build</li> <li><code>DOCKER_EXTRA_ARGS</code>: if running builds in Docker, any additional args to pass to the container; e.g. use this to mount a <code>tmpfs</code> if needed</li> <li><code>DONT_USE_COMMENTS</code>: only update GitHub statuses after the check completes, instead of commenting on each pull request as the alibuild user</li> <li><code>INSTALL_ALIBOT</code>, <code>INSTALL_ALIBUILD</code>: a slug (<code>&lt;org&gt;/&lt;repo&gt;@&lt;tag&gt;#egg=&lt;package&gt;</code>) specifying the ali-bot and alibuild versions to install for this check</li> <li><code>JOBS</code>: how many CPU cores to use for building</li> <li><code>NO_ASSUME_CONSISTENT_EXTERNALS</code>: auto-generate a build identifier to keep builds of different pull requests apart. This uses more disk space overall, but can speed up rebuilds, since build artifacts are kept for each pull request.</li> <li><code>PACKAGE</code>: the package (as declared in alidist) to build for the check</li> <li><code>PR_BRANCH</code>: look for pull requests against this branch</li> <li><code>PR_REPO</code>: look for pull requests in this repository</li> <li><code>PR_REPO_CHECKOUT</code>: check out the repository to be tested into this directory</li> <li><code>REMOTE_STORE</code>: use this as alibuild's <code>--remote-store</code>, for caching</li> <li><code>TRUST_COLLABORATORS</code>: automatically test PRs from people who have committed to the same repo before, without waiting for approval from someone else</li> <li><code>TRUSTED_USERS</code>, <code>TRUSTED_TEAM</code>: trust pull requests from these users (i.e. test them without requiring approval)</li> <li><code>ONLY_RUN_WHEN_CHANGED</code>: a space-separated list of paths. The check will only be run if the given pull request contains any changes under any of these paths. If not, the check will be skipped and marked as successful with an appropriate message.</li> </ul> <p>In order to add a new pull request check for a repository, and a checker for the required platform/container exists already, just add a <code>*.env</code> file in the appropriate directory in ali-bot.</p> <p>If you add a new check, make sure to update the appropriate repository's GitHub action that cleans up broken statuses to include your new check. For example, in alidist, update this file, or this file for O2.</p>"},{"location":"infrastructure-pr-testing/#setup-your-environment","title":"Setup your environment","text":"<p>Set up your Nomad environment as described here. Job declarations for the pull request checkers are stored inside the <code>ci/</code> subdirectory of the ci-jobs repository.</p> <p>See this section of the ALICE Nomad docs for instructions on deploying CI builders.</p>"},{"location":"infrastructure-pr-testing/#listing-active-pr-checkers","title":"Listing active PR checkers","text":"<p>In order to see the list of the running prs you can do:</p> <pre><code>nomad job status ci-\n</code></pre> <p>where the resulting job names will follow the convention <code>ci-&lt;mesos role&gt;-&lt;container&gt;[-&lt;suffix&gt;]</code>.</p> <p>This matches the subdirectories of <code>ali-bot/ci/repo-config/</code>. For example, the <code>ci-mesosci-slc9-o2physics</code> checker will pick up its <code>.env</code> files from <code>ali-bot/ci/repo-config/mesosci/slc9-o2physics/</code>.</p> <p>Each checker will have one or more instances with the same configuration. You can see these by running, e.g.:</p> <pre><code>nomad job status ci-mesosci-slc8-gpu\n</code></pre> <p>You can check what each instance is doing by getting its allocation ID, then running:</p> <pre><code>nomad alloc logs -stderr -tail -f &lt;alloc ID&gt;\n</code></pre>"},{"location":"infrastructure-pr-testing/#scaling-the-number-of-checkers","title":"Scaling the number of checkers","text":"<p>See here for the procedure.</p> <p>Running builders should not be affected by this operation. This will only add builders if you increased <code>num_builders</code> or delete some if you decreased it.</p> <p>The builders know how many there are of the same type though the <code>config/workers-pool-size</code> file. Nomad will automatically update this file for you when you deploy the updated job declaration.</p>"},{"location":"infrastructure-pr-testing/#creating-a-new-checker","title":"Creating a new checker","text":"<p>In order to add a new checker, you need to add both a Nomad job declaration by creating a new YAML file in <code>ci-jobs/ci/</code>. Assuming you want to add a checker that runs two parallel builders as the <code>mesosci</code> user and compiles software using an <code>slc9</code> container, create a file called <code>ci-jobs/ci/mesosci-slc9-foobar.yaml</code> containing the following:</p> <pre><code>---\nrole: mesosci\narch: slc9\nconfig_suffix: '-foobar'\nnum_builders: 2\n</code></pre> <p>You can deploy the checkers declared using this file by running:</p> <pre><code>levant render -var-file mesosci-slc9-foobar.yaml | nomad job plan -  # make sure scheduling is fine\nlevant render -var-file mesosci-slc9-foobar.yaml | nomad job run -   # actually redeploy the job\n</code></pre> <p>You also need to tell the new checker what it should build and where it should look for incoming pull requests. Do this by creating configuration files in <code>ali-bot/ci/repo-config/mesosci/slc9-foobar/</code> (assuming the same parameters as above).</p> <p>The easiest thing to do is to copy an existing <code>.env</code> file that you want to mimic and change the <code>CI_NAME</code> and <code>CHECK_NAME</code> variables.</p> <p>For example, if you want to test PRs in the https://github.com/AliceO2Group/AliceO2 repository by compiling O2Suite and running O2's and O2Physics' unit tests, adapt the following:</p> <pre><code>CI_NAME=build_O2_o2\nCHECK_NAME=build/O2/o2\nPACKAGE=O2Suite\nALIBUILD_DEFAULTS=o2\nPR_REPO=AliceO2Group/AliceO2\nPR_REPO_CHECKOUT=O2\nPR_BRANCH=dev\nTRUST_COLLABORATORS=true\nDONT_USE_COMMENTS=1\nDEVEL_PKGS=\"$PR_REPO $PR_BRANCH $PR_REPO_CHECKOUT\nAliceO2Group/O2Physics master\nalisw/alidist master\"\nALIBUILD_O2_TESTS=1\nALIBUILD_O2PHYSICS_TESTS=1\n</code></pre> <p>The <code>.env</code> files are in shell syntax. They are sourced by the CI builders, but some utilities (<code>list-branch-pr</code> and <code>ci-status-overview</code>) also parse them using Python's <code>shlex</code> library, so try not to use overly complex Bash features. Try to use only literal strings for the <code>PR_REPO</code>, <code>PR_BRANCH</code>, <code>CHECK_NAME</code>, <code>TRUST_COLLABORATORS</code>, <code>TRUSTED_USERS</code> and <code>TRUSTED_TEAM</code> variables, since the Python tools parse these. For other variables, feel free to use variable substitution with the usual shell syntax.</p>"},{"location":"infrastructure-pr-testing/#updating-the-pr-checker-inner-loop","title":"Updating the PR checker inner loop","text":"<p>Sometimes one might need to update the inner loop of the PR checking, without having to restart the checker itself. This is done automatically for any updates of the <code>ali-bot/ci/build-loop.sh</code> and <code>ali-bot/ci/build-helpers.sh</code> files.</p> <p>Upgrades will be picked up at the next iteration of the PR builder, so you might still have to wait for the current one to finish before you can see your updates deployed.</p> <p>Updates to <code>ali-bot/ci/continuous-builder.sh</code> are also picked up, but less frequently.</p>"},{"location":"infrastructure-pr-testing/#restarting-a-checker","title":"Restarting a checker","text":"<p>In some cases, builders need to be restarted.</p> <p>See here for the procedure.</p> <p>This will redeploy the same configuration, but the <code>ali-bot</code> scripts will be taken from the master branch and <code>continuous-builder.sh</code> will be run again.</p>"},{"location":"infrastructure-pr-testing/#inspecting-the-checkers","title":"Inspecting the checkers","text":"<p>You can stream the logs of any CI builder instance easily -- see here how to do this.</p> <p>If you want to interactively log in to any instance, run:</p> <pre><code>nomad alloc exec &lt;alloc ID&gt; sh -c 'export TERM=xterm-256color HOME=$NOMAD_TASK_DIR PS1=\"\\\\u@\\\\h \\\\w \\\\\\$ \"; cd; exec bash -i'\n</code></pre> <p>This will give you a shell in the builder's home directory, where it stores its workarea.</p> <p>Log files are in the <code>$NOMAD_ALLOC_DIR/logs</code> directory.</p> <p>The checkers react to some special files, which can be created in their home directory. In particular:</p> <ul> <li><code>config/silent</code> with non empty content means that the checker will not report issues to the github PR page associated with the checks being done.</li> <li><code>config/debug</code> will force additional debugging output.</li> <li><code>config/workers-pool-size</code> will force the number of checkers currently active.   This is normally created and updated automatically by Nomad.</li> <li><code>config/worker-index</code> will force the index of the current instance of the checker.</li> </ul>"},{"location":"infrastructure-pr-testing/#monitoring-the-checkers","title":"Monitoring the checkers","text":"<p>The CI system is monitored using a dedicated Grafana dashboard.</p> <p>Builders are monitored in Monalisa. In particular you can use aliendb9 and look at the <code>github-pr-checker/github.com/github-api-calls</code> metric to know how many API calls are being done by the system.</p> <p>You can also get a detailed view the activity of the builders in our Build Infrastructure Cockpit. If you are interested in extending the reports, please contact us.</p> <p>Some of the CI machines are also included in the IT Grafana dashboard. Notice this includes also machines which do not run CI builds.</p> <p>There is also a dashboard that shows the status of each check and pull request. In case of outages for larger problems, this can be useful to find failed PRs, or to find out when the problems started (since PRs are sorted newest-first).</p>"},{"location":"infrastructure-pr-testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"infrastructure-pr-testing/#empty-logs","title":"Empty logs","text":"<p>Empty logs can happen in the case the build fails in some pre-alibuild steps and the harvesting script is not able or not allowed to fetch logs. In particular, due to the criticality of some operations, logs which might contain sensitive information are not retrieved, to avoid exposing them to unprivileged ALICE users. Maintainers of the build infrastructure can follow the instructions in the report to retrieve them.</p> <p>That said, the vast majority of the \"missing logs issues\" are due to the following two items:</p> <ul> <li>Wrong tag / commit / url when checking out the code. Make sure you review any tag and commit you changed in your PR to make sure they are actually existing. Possibly check by hand all the modified tags with <code>git clone -b &lt;tag&gt; &lt;url&gt;</code>.</li> <li>Issues with the infrastructure backend not directly under our control, in particular gitlab and github. You can review if there was any known issues by going to either the github status page or the CERN Service Status Board.</li> </ul> <p>Failing those (or if you are unsure) feel free to contact us directly either on mattermost or by adding a comment to your PR.</p>"},{"location":"infrastructure-publisher/","title":"Release publishing","text":""},{"location":"infrastructure-publisher/#publishing-of-packages","title":"Publishing of packages","text":"<p>Packages are published using ali-bot/publish scripts.  This happens in different places depending if we are deploying on CVMFS or Alien. The procedure is automatic and in principle there is no need for babysitting it, however in case of troubles you can do the following:</p>"},{"location":"infrastructure-publisher/#troubleshooting-cvmfs","title":"Troubleshooting CVMFS","text":""},{"location":"infrastructure-publisher/#access-to-the-publisher-machines","title":"Access to the publisher machines","text":"<ul> <li>SSH as your username to <code>cvmfs-alice.cern.ch</code> or   <code>cvmfs-alice-nightlies.cern.ch</code> depending on   what you are publishing (ask to be added to the self managed lxcvmfs-alice for authorization).</li> <li>Follow the instructions given at the logon by the MOD</li> <li>Logs are in <code>~/publisher/log</code></li> </ul>"},{"location":"infrastructure-publisher/#issue-with-missing-root-libraries","title":"Issue with missing ROOT libraries","text":"<p>For some yet to be understood reason sometimes ROOT is published with a <code>-&lt;N&gt;</code> revision, while <code>-&lt;N+1&gt;</code> is available. This leads to errors like:</p> <pre><code>o2-analysistutorial-histograms-full-tracks: error while loading shared libraries: libGenVector.so.6.24: cannot open shared object file: No such file or directory\n</code></pre> <p>when running in hyperloop. In order to workaround the issue, for the moment, the solution is to add by hand a symlink to the existing folder. This can be done by:</p> <ul> <li><code>ssh cvmfs-alice.cern.ch</code></li> <li><code>sudo -i -u cvalice</code></li> <li>Go to the ROOT folder and start a transaction</li> </ul> <p><pre><code>cd /cvmfs/alice.cern.ch/el7-x86_64/Packages/ROOT/\ncvmfs_server transaction alice.cern.ch\n</code></pre> * Find the missing ROOT and create a symlink to the next available one. E.g. <code>ln -s v6-24-02-24 v6-24-02-23</code>. * Close the transaction <code>cd &amp;&amp; cvmfs_server transaction alice.cern.ch</code>.</p> <p>Things should be then back in business in a few minutes, time for CVMFS to propagate the changes everywhere.</p>"},{"location":"infrastructure-publisher/#troubleshooting-alien","title":"Troubleshooting ALIEN","text":"<p>See the <code>publish-alien</code> Nomad job.</p>"},{"location":"infrastructure-publisher/#troubleshooting-rpms","title":"Troubleshooting RPMS","text":"<p>RPMS are also created using <code>aliPublishS3</code> in Nomad. See the dedicated documentation.</p>"},{"location":"infrastructure-publisher/#add-new-packages","title":"Add new packages:","text":""},{"location":"infrastructure-publisher/#cvmfs","title":"CVMFS","text":"<p>Packages published on CVMFS can be configured via the <code>aliPublish.conf</code> file. Apart from having your changes in master, no further action is required.</p> <p>Builds of O2PDPSuite from the <code>async</code> branch are also published on CVMFS using [<code>aliPublish-async.conf</code>][async-conf].</p> <p>In addition, the AliDPG package is handled specially and published to <code>noarch</code> using <code>aliPublish-noarch.conf</code>.</p>"},{"location":"infrastructure-publisher/#rpms","title":"RPMS","text":"<p>If you need to generate a new RPM package, the configuration is in <code>ali-bot/publisher/aliPublish-rpms-cc8.conf</code> and <code>aliPublish-s3-updatable-rpms.conf</code>. Once you have updated it and merged in alisw/ali-bot, the publisher will pick your changes up automatically.</p>"},{"location":"infrastructure-publisher/#start-publishing-on-a-new-architecture","title":"Start publishing on a new architecture","text":"<p>In order to publish Run 2 packages on another architecture on CVMFS, symlinks for the AliDPG package must be in place.</p> <p>AliDPG is built on CentOS 8, but published to a special <code>noarch</code> architecture on CVMFS and AliEn.</p> <p>AliDPG is always loaded explicitly, as the last package in a list, like <code>AliPhysics/v5-09-59a-01-1,AliDPG/prod-202209-01-1</code>. Because <code>alienv</code> loads all packages from the same architecture, the availability of the AliPhysics package determines where we look for the AliDPG package. As AliDPG just provides a shell script and some uncompiled ROOT macros, it doesn't matter which architecture it was built on, so we can share AliDPGs between all architectures by putting them in <code>noarch</code>.</p> <p>To facilitate this, the following symlinks must be created (remember to wrap this in a CVMFS transaction):</p> <pre><code>arch='&lt;the new architecture you want to add, e.g. \"el8-x86_64\"&gt;'\ncd /cvmfs/alice.cern.ch\nln -svnf ../../../noarch/Modules/modulefiles/AliDPG \"$arch/Modules/modulefiles/AliDPG\"\nln -svnf ../../noarch/Packages/AliDPG \"$arch/Packages/AliDPG\"\n</code></pre> <p>TODO: This hasn't been done for O2DPG yet; that package is pulled in by O2PDPSuite, so the publishing procedure is more complicated there.</p>"},{"location":"infrastructure-release-process-o2/","title":"Release process O2PDPSuite","text":""},{"location":"infrastructure-release-process-o2/#o2pdpsuite-release-process-for-epns","title":"O2PDPSuite release process for EPNs","text":"<ol> <li> <p>O2PDPSuite is a meta package which contains O2, QualityControl, DataDistribution and all their dependencies.</p> </li> <li> <p>Multiple O2PDPSuite versions can be installed on the EPN in parallel without interfering with each other. The default O2PDPSuite version is taken from CONSUL. The operators have the possibility to overwrite the default version for each partition via the AliECS GUI. This means that multiple partitions can run simultaneously using different software versions.</p> </li> <li> <p>We categorize the O2PDPSuite versions we deploy in the following 3 categories:</p> <ul> <li>Official releases: fully supported stable versions, to be used as default CONSUL setting, usually updated once per week on Monday in sync with the FLPSuite upgrade.</li> <li>Test versions for detectors: installed upon request of detectors / other groups (e.g. EPN) with a newer version of O2. These versions are tested with the same Full System Test as official releases, but they do not undergo the Monday software workout. They are partially supported, particularly it is important for us to get feedback in case of issues so it can be fixed for the next release. But if a problem with such a version cannot be solved easily, the user should go back to the fully supported official release.</li> <li>Internal test versions: We do not provide support for other users, these versions are mostly for internal tests. We do not prevent anyone from testing, and please let us know in case there are errors, but support is on a best effort basis only.</li> </ul> </li> <li> <p>We will set up a web site where we list all versions currently installed, and what support we provide for each of them.</p> </li> <li> <p>We will have the following software builds:</p> <ul> <li>Nightly test builds: These are basically the builds we have had so far. They are based on the currently installed FLPSuite on all days except Monday, and on the newest FLPSuite on Monday. In this way, they should be compatible with the software running on the FLP if installed in the morning (on Mondays after the FLPSuite update). The builds use the nightly O2 tag, and several packages (DD, QC, Monitoring, ODC, DDS, O2DPG, and some others on demand) from alidist/master, to have the latest software for tests.</li> <li>Weekly release build: Created on Thursday morning, based on the latest available FLPSuite, using the O2 tag of that night, and Monitoring, DDS, ODC, O2DPG from alidist master of that morning.</li> <li>Manual builds on demand, based either on a nightly test build, or on the weekly release build, or a specified alidist branch, with specific packages manually overridden to a specific version.</li> </ul> </li> <li> <p>Release coordination process:</p> <ul> <li>The weekly build we create on Thursday is the candidate we want to run as default from the next Monday on.</li> <li>We will install it on Thursday on the EPNs, and announce the changes to the previous build at the release coordination meeting on Thursday.</li> <li>The build is for the next FLPSuite, so it may be that it is not compatible with the currently running FLPSuite.</li> <li>It can be tested using the FLP Staging running the new FLPSuite.</li> <li>In case the new FLPSuite is not yet available during build time, we build against the old FLP Suite. Then, a manual build against the new FLPSuite must be done before Monday morning.</li> <li>If the software workout on Monday succeeds, this will become the new default version in CONSUL.</li> <li>If RC wants multiple release builds for Monday (e.g. with 2 different DataDistribution versions), they can request these and we will create the corresponding manual builds in time.</li> <li>In addition, we will always deploy the latest nightly software build on Monday morning as alternative version.</li> </ul> </li> <li> <p>Build names:</p> <ul> <li>The weekly release and manual release builds will follow the following naming scheme, to make it clear which DD version they contain, and what FLPSuite they are based on: <code>O2PDPSuite-epn-%Y%m%d-DD[VERSION]-flp-suite-v[VERSION]</code>.</li> <li>Daily test builds will have just the date, and in case of 2 builds in addition the time, as before.</li> </ul> </li> <li> <p>Updating default software version in CONSUL:</p> <ul> <li>Regularly, on Monday morning the default in CONSUL will be changed to the new release version.</li> <li>Any test version installed by PDP (regardless whether requested by a detector or for an internal test) will not be set in CONSUL, but must be enabled per partition in the AliECS GUI.</li> <li>If RC wants to update to a new version, i.e. make a test version the default version under the week, they can call the PDP oncall for the change, or for the revert if needed, or just change the CONSUL values by themselves.</li> </ul> </li> <li> <p>Software tests</p> <ul> <li>All PRs to O2 are tested in a small full system test with a TF consisting of 5 collisions.</li> <li>When deployed to the EPN farm, all O2 versions are tested with a 15 minute full system test replaying full PbPb TFs at 50kHz interaction rate on a single node, running the full synchronous processing workflow.</li> <li>QC and calibration tasks are gradually added to the full system test.</li> </ul> </li> </ol>"},{"location":"infrastructure-release-process/","title":"Release process AliRoot / AliPhysics","text":"<p>This is to document the release process of AliRoot / AliPhysics.</p>"},{"location":"infrastructure-release-process/#prerequisites","title":"Prerequisites","text":"<p>You should be roughly familiar on how to run a Github Actions workflow by hand and you should ask for permissions to do so.</p> <p>Unless otherwise specified, always use the master branch of the workflow definition.</p>"},{"location":"infrastructure-release-process/#creating-a-release","title":"Creating a release","text":"<p>The easiest way to create a release is to trigger the corresponding GitHub Actions in each repository. It is important to do this in the following order!</p> <p>For each workflow, replace the <code>XXy</code> string in the release tag with the one you'd like to build. This will be two digits and a lowercase letter. The last workflow (in AliPhysics) will need the same tag as the other two, but with <code>-01</code> appended.</p> <ol> <li>\"Prepare AliRoot/AliPhysics tag\" in alidist</li> <li>\"Prepare AliRoot tag\" in AliRoot</li> <li>\"Prepare AliPhysics tag\" in AliPhysics</li> <li>Start a build in Jenkins.    Change the following settings, replacing <code>XXy</code> with the tag name you created above:    <pre><code>ALIDIST_SLUG=alisw/alidist@AliPhysics-v5-09-XXy-01\nARCHITECTURE=slc7_x86-64\nPACKAGE_NAME=AliPhysics\nOVERRIDE_TAGS=\"AliPhysics=v5-09-XXy-01 AliRoot=v5-09-XXy\"\n</code></pre></li> </ol>"},{"location":"infrastructure-release-process/#patching-old-aliroot-v5-08-releases","title":"Patching old (\u2264 AliRoot-v5-08) releases","text":"<p>The transition from <code>AliRoot-v5-08</code> to <code>AliRoot-v5-09</code> involved a cleanup of large files, which were removed from the history of the official Github repository and left in a CERN-hosted GitLab repository.</p> <p>For this reason any patch release on top of an old release should be tagged from that repository. In particular you have the following branches:</p> <ul> <li>v5-09-18b-01 (SLC5, alidist: legacy/v5-09-18)</li> <li>v5-08-13zm-01-cookdedx (SLC5, alidist: IB/v5-08/prod)</li> <li>v5-08-13q-p14-01-cookdedx (SLC5, alidist: IB/v5-08/prod)</li> <li>v5-08-13q-p14-01 (SLC5, alidist: IB/v5-08/prod)</li> </ul>"},{"location":"infrastructure-relval/","title":"Release validation operations","text":"<p>The release validation of AliRoot communicates its results on Jira. Before starting a release validation, we create a Jira ticket and take note of its ID (for instance, ALIROOT-1234).</p> <p>Then we start the AliRootDPGValidation. Normally, the only parameter that needs changing is the JIRA_ISSUE one, where one must specify the ID of the just created ticket. In case no other parameter is changed, the release validation will:</p> <ul> <li>Automatically tag AliRoot, AliPhysics and AliDPG from their master branches (the tag will be clearly marked as \u201crc\u201d, as in \u201crelease candidate\u201d)</li> <li>Build the three of them, using the master of alidist</li> <li>Wait for their deployment on CVMFS: we use the nightlies repository, /cvmfs/alice-nightlies.cern.ch</li> </ul> <p>Start the validation script for Reconstruction first, then General Purpose Monte Carlo.</p>"},{"location":"infrastructure-relval/#essential-user-guide","title":"Essential User Guide","text":"<p>All the release validations performed are available at:</p> <p>https://ali-ci.cern.ch/release-validation/</p>"},{"location":"infrastructure-relval/#essential-operations-guide","title":"Essential Operations Guide","text":""},{"location":"infrastructure-relval/#managing-data-on-eos","title":"Managing data on EOS","text":"<p>EOS and its XRootD interface are used by the release validation:</p> <ul> <li>for storing reference data</li> <li>for storing validation results</li> </ul> <p>In order to manipulate EOS data you need to have a valid X.509 proxy. If you do not have EOS installed you can use it from the <code>alisw/slc6-cvmfs</code> container which has it preinstalled.</p> <p>Assuming your proxy to be used for EOS is available under <code>~/.globus/eos-proxy</code> you can start the container like the following:</p> <pre><code>docker run -it --rm                                                   \\\n  -privileged                                                         \\\n  -v ~/.globus:/root/.globus:ro                                       \\\n  -e X509_USER_PROXY=/root/.globus/eos-proxy                          \\\n  -e X509_CERT_DIR=/cvmfs/grid.cern.ch/etc/grid-security/certificates \\\n  alisw/slc6-cvmfs                                                    \\\n  parrot_run eos root://eospublic.cern.ch/\n</code></pre> <p>Where <code>parrot_run</code> is used to enable CVMFS (only used for reading the CA certificates). This command sends you straight to the EOS prompt. Note that the <code>-privileged</code> option is required by Parrot.</p> <p>If you have EOS installed on your machine you can simply export a couple of environment variables and start EOS afterwards:</p> <pre><code>export X509_USER_PROXY=&lt;path_to_eos_proxy&gt;\nexport X509_CERT_DIR=/cvmfs/grid.cern.ch/etc/grid-security/certificates\nexport EOS_MGM_URL=root://eospublic.cern.ch\neos\n</code></pre>"},{"location":"infrastructure-relval/#remove-old-release-validations","title":"Remove old release validations","text":"<p>From the EOS prompt on <code>eospublic.cern.ch</code> move to the results output folder:</p> <pre><code>cd /eos/opstest/pbuncic/output/\n</code></pre> <p>You can then list the directories with <code>ls</code> and remove them one by one with:</p> <pre><code>rm -r\n</code></pre>"},{"location":"infrastructure-relval/#used-quota-on-eos","title":"Used quota on EOS","text":"<p>From the EOS prompt on <code>eospublic.cern.ch</code> query the quota for our directory:</p> <pre><code>quota /eos/opstest/pbuncic/\n</code></pre>"},{"location":"infrastructure-relval/#stage-new-data-on-eos-from-alien","title":"Stage new data on EOS from AliEn","text":"<p>This operation requires a working AliEn installation, we will be assuming that you are using AliEn from aliBuild. Enter the AliEn environment:</p> <pre><code>alienv enter AliEn-Runtime/latest\n</code></pre> <p>Now get a valid token and proxy:</p> <pre><code>alien-token-init &lt;your_alien_username&gt;\n</code></pre> <p>Now get and use the staging data script to stage new data:</p> <pre><code>git clone https://github.com/alisw/release-validation\ncd release-validation/\n./stage-data.sh /alice/data/2016/LHC16e/000252858/raw/ 300\n</code></pre> <p>where:</p> <ul> <li>the first parameter is the AliEn path (without the <code>alien://</code> prefix) where    raw data can be found</li> <li>the second parameter is the number of files to stage, which will be picked    randomly among the full raw list</li> </ul> <p>The script will exit on the first error. You can re-run it many times until it converges to the full list being staged on EOS. Data already copied is skipped.</p> <p>The script will echo the path of a <code>.done</code> file containing the EOS paths to be used as a dataset for a release validation. In order to make this file usable:</p> <ul> <li>add it as a <code>.txt</code> file in the <code>datasets/</code> directory of the    <code>release-validation</code> repository, and push it</li> <li>edit the Jenkins job in order to add the dataset name (file name without the    <code>.txt</code> extension) to the drop-down list associated to the <code>DATASETS</code> Jenkins    variable</li> </ul>"},{"location":"infrastructure-relval/#proxy-certificate","title":"Proxy certificate","text":"<p>Release validation uses a Grid proxy certificate mapped to the alibot EOS/CERN service account on eospublic.cern.ch.</p> <p>As CERN does not allow service accounts to own certificates, we are using a host certificate for this purpose. The corresponding node is managed by the CERN Puppet infrastructure therefore its certificate will be automatically renewed. Certificate and key will be found under <code>/etc/grid-security</code> on the very host.</p> <p>Release validation is configured to preventively fail at start if the proxy certificate is going to expire soon (in order not to fail in the middle of a job with errors difficult to catch).</p> <p>First off, connect to <code>alibuild-frontend01</code>. Once there, <code>rsync</code> the certificate directory to <code>aiadmin.cern.ch</code> (a login node managed by CERN IT):</p> <pre><code>rsync -av /etc/grid-security/ youruser@aiadm.cern.ch:eos-cert/\n</code></pre> <p>Connect to <code>aiadm.cern.ch</code>, then:</p> <pre><code>cd eos-cert/\ngrid-proxy-init -cert hostcert.pem -key hostkey.pem -out eos-proxy.pem -valid 9000:0\n</code></pre> <p>Just make sure the proxy is shorter than the issuing certificate by tuning the <code>9000</code> number (in hours). A warning is issued in case proxy is longer.</p> <p>Now, store the proxy on <code>tbag</code> (the CERN IT facility for deploying secrets, integrated with Puppet):</p> <pre><code>tbag set --hg alibuild/mesos/slave --file eos-proxy.pem eos-proxy\n</code></pre> <p>If you want to force the update on every node and don't want to wait for automatic Puppet runs, do everywhere (with <code>pdsh</code>, <code>mpssh</code> or similar tools):</p> <pre><code>puppet agent -tv\n</code></pre> <p>Additionally, you can verify the proxy information by running:</p> <pre><code>voms-proxy-info -file eos-proxy.pem\n</code></pre> <p>Note that on some nodes (not Puppet-managed) proxy has to be deployed manually as <code>/secrets/eos-proxy</code> with mode <code>0400</code>. This can be done with:</p> <pre><code>for x in alientest02.cern.ch alientest06.cern.ch  alientest07.cern.ch pcalienstorage.cern.ch; do\n  rsync --chown=0400 eos-proxy.pem root@$x:/secrets/eos-proxy\ndone\n</code></pre> <p>On <code>aiadmin</code>, everything can be now deleted:</p> <pre><code>cd ; rm -rf eos-cert/\n</code></pre>"},{"location":"infrastructure-repository/","title":"aliBuild Package Repository","text":""},{"location":"infrastructure-repository/#essential-operation-guides","title":"Essential operation guides","text":"<ul> <li>Creating the bucket</li> <li>Access via RClone</li> </ul>"},{"location":"infrastructure-repository/#creating-the-bucket","title":"Creating the bucket","text":"<p>Creating the bucket should not be needed unless some disaster happens. The current instructions to do so are:</p> <ul> <li>Go to the openstack dashboard select \"Object Store &gt; Containers\" and add a new container.</li> <li>Create a set of ec2 credentials for that container, as explained on the [CERN S3 pages][clouddocs].</li> <li>Make sure with CERN/IT that the <code>ali-bot</code> S3 local user is still available.</li> <li>Make sure no expiration policy is set for the packages.</li> <li>Set the access policy to the contents of <code>ali-marathon/s3/alibuild-repo.json</code>. See clouddocs how to do that.</li> <li>Verify that using the <code>ali-bot</code> access_key / secret_key you can write files.</li> </ul>"},{"location":"infrastructure-repository/#accessing-via-rclone","title":"Accessing via RClone","text":"<p>You can use RClone to access the repository with the following configuration:</p> <pre><code>export RCLONE_CONFIG_ALIBUILD_TYPE=\"s3\"\nexport RCLONE_CONFIG_ALIBUILD_PROVIDER=\"Ceph\"\nexport RCLONE_CONFIG_ALIBUILD_ENV_AUTH=\"false\"\nexport RCLONE_CONFIG_ALIBUILD_ACCESS_KEY_ID=\nexport RCLONE_CONFIG_ALIBUILD_SECRET_ACCESS_KEY_ID=\nexport RCLONE_CONFIG_ALIBUILD_REGION=\nexport RCLONE_CONFIG_ALIBUILD_BUCKET_ACL=\"public-read\"\nexport RCLONE_CONFIG_ALIBUILD_ENDPOINT=https://s3.cern.ch\nexport RCLONE_VERBOSE=4\n\nrclone listremotes\nrclone ls alibuild:alibuild-repo/\n</code></pre> <p>In order to actually write to the repository you need to have the valid access key / secret set. Alternatively you can have the appropriate stanza in <code>~/.config/rclone/rclone.conf</code>. </p>"},{"location":"infrastructure-rpms/","title":"Generation of RPMs for the O2 packages","text":""},{"location":"infrastructure-rpms/#rationale","title":"Rationale","text":"<p>Some clients of O2 software need to use RPMs to deploy O2 software and its dependencies. We support two kind of RPM builds:</p> <ul> <li>Parallel installable RPMs, where the version of the packages is   actually part of the name, allowing parallel installation a-la CVMFS.</li> <li>Updatable RPMs, which behave like common RPMs for Centos / RHEL.</li> </ul> <p>The RPM creation is not a rebuild of the tarballs which are usually deployed on CVMFS, but a mere repackaging of the tarballs, via the same script which does the publishing on CVMFS. The script itself is called <code>aliPublish</code> and as usual it's part of the  alisw/ali-bot repository.</p> <p>For the RPM case, in particular, the script runs in Nomad as a <code>publish-rpm-*</code> job. The script runs asynchrounously and publishes packages as specified by the configurations for parallel and updateable RPMs.</p>"},{"location":"infrastructure-rpms/#nomad-job-management","title":"Nomad job management","text":"<p>Just like CI and Jenkins builders, RPM publishers are configured as templated Nomad jobs.</p> <p>They are declared using one YAML file for each architecture. For instance, for the Alma 8 RPMs, see <code>ci-jobs/rpm-creation/el8.yaml</code>:</p> <pre><code>---\narch: el8.x86_64\nconfigs:\n  - aliPublish-rpms-cc8.conf\n  - aliPublish-s3-updatable-rpms.conf\n</code></pre> <p>This declares the architecture for which RPMs are created as <code>arch</code>, and the configuration files from <code>ali-bot/publish/</code> to use as <code>configs</code>.</p> <p>Updates to <code>aliPublishS3</code> or the configuration files are picked up automatically between runs.</p>"},{"location":"infrastructure/","title":"Infrastructure","text":"<p>The following pages contain implementation details of various parts of the build infrastructure. They are not of general need, but serve as reference to operate the system.</p> <p>You can find further information on how aliBuild works in the aliBuild documentation.</p> <p>Further troubleshooting information is privately available in the repository:</p> <p>https://gitlab.cern.ch/ALICEDevOps/aliops.git/</p>"},{"location":"infrastructure/#tasks","title":"Tasks","text":"<ul> <li>Release process AliRoot / AliPhysics</li> <li>Release process O2PDPSuite</li> <li>O2 stable branches</li> <li>Nightly builds</li> <li>CVMFS releases</li> <li>Testing of Pull Requests (continuous integration)</li> <li>Build Logs</li> <li>Release Publishing</li> <li>RelVal</li> <li>AliBI User Guide</li> <li>Setting up automatic release builds</li> <li>Generation of RPMs</li> <li>Known tradeoffs</li> <li>Building Docker images with Packer</li> </ul>"},{"location":"infrastructure/#infrastructure","title":"Infrastructure","text":"<ul> <li>Using Nomad, Consul and Vault</li> <li>Nomad cluster setup</li> <li>MacOS builder setup</li> <li>Virtual and physical machines</li> <li>AliEn VoBox</li> <li>Web Frontend</li> <li>Jenkins</li> <li>AliBuild S3 Repository</li> <li>AliBI</li> <li>Setting up automatic release builds</li> </ul>"}]}